#!/usr/bin/env python3
"""
Figure 2 Panel Generation Script

This script generates example images for Figure 2 panels D and E, showing
spots AND clusters with varying volumes and intensities.

Uses the actual UNet-based cluster detection from the RNAscope pipeline
(same as main_one_folder.py), including:
- Label pruning (remove_labels_touching_spots)
- Proper spot filtering with break_sigma

Generates:
- Overview images with spots and clusters
- Zoomed images with colorbars for cluster intensity (in mRNA units)
- Zoomed images with colorbars for cluster size (in voxels/µm³)

Output:
    example_images/figure2/
        panel_D/  (green channel - mHTT1a clusters)
        panel_E/  (orange channel - full-length mHTT clusters)
"""

import os
import sys
import json
from pathlib import Path
import numpy as np
import pandas as pd
import h5py
from tifffile import imwrite
from skimage import measure
from skimage.measure import regionprops
import matplotlib.pyplot as plt
from matplotlib.colors import Normalize, LogNorm
from matplotlib import cm
from matplotlib.patches import Rectangle
import matplotlib.patches as mpatches
from PIL import Image, ImageDraw
import blosc
import traceback
import torch

# Add parent directories for imports
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# Add user_code for config
sys.path.insert(0, str(Path(__file__).parent.parent.parent / 'user_code'))

# Import RNAscope class
from rna_scope_backbone.RNAscope import RNAscopeclass

# Import figure styling
from figure_config import FigureConfig, apply_figure_style
apply_figure_style()

# Import global config
sys.path.insert(0, str(Path(__file__).parent.parent))
from results_config import CHANNEL_PARAMS, SLICE_DEPTH, PIXELSIZE, VOXEL_SIZE, H5_FILE_PATH, CV_THRESHOLD, EXCLUDED_SLIDES

# Output directory
OUTPUT_DIR = Path(__file__).parent / 'output' / 'example_images' / 'figure2'

# Path to pre-computed slide-specific peak intensities (from fig_aggregate_scaling_v3.py)
PEAK_INTENSITIES_CSV = Path(__file__).parent.parent / 'draft_figures' / 'output' / 'aggregate_scaling' / 'peak_intensities_per_slide.csv'

# Path to negative control thresholds (95th percentile of negative control intensity per slide/channel)
PHOTON_THRESHOLDS_CSV = Path(__file__).parent / 'output' / 'photon_thresholds.csv'

# Pixel size for conversions (from results_config.py, convert nm to µm)
PIXEL_SIZE_XY = PIXELSIZE / 1000  # µm per pixel (162.5nm -> 0.1625µm)
SLICE_DEPTH_UM = SLICE_DEPTH / 1000  # µm per z-slice (500nm -> 0.5µm)
VOXEL_VOLUME_UM3 = VOXEL_SIZE  # µm³ per voxel (from results_config.py)

# Scale bar sizes (in µm)
SCALE_BAR_OVERVIEW = 50  # 50 µm for full FOV images
SCALE_BAR_ZOOM = 10      # 10 µm for zoom insets

# Zoom box size
ZOOM_SIZE = 256  # pixels (256 * 0.1625 = 41.6 µm)

# Channel indices in NPZ files
CHANNEL_MAP = {
    'blue': 0,   # mDAPI
    'green': 1,  # sFITC (mHTT1a)
    'orange': 2, # sCY3 (full-length mHTT)
    'red': 3,    # sCY5 (Darp)
}

# Local model paths
LOCAL_MODEL_PATHS = {
    'green': '/home/grunwaldlab/development/rna_scope/training_cluster/training_green_yellow/checkpoint/best_checkpoint.pytorch',
    'orange': '/home/grunwaldlab/development/rna_scope/training_cluster/training_green_yellow/checkpoint/best_checkpoint.pytorch',
    'blue': '/home/grunwaldlab/development/rna_scope/training_cluster/training_dapi/checkpoint/best_checkpoint.pytorch',
}

# Local YAML config paths
LOCAL_YAML_PATHS = {
    'green': '/home/grunwaldlab/development/rna_scope/predict_yamls/confg_prediction_green_yellowchannel.yaml',
    'orange': '/home/grunwaldlab/development/rna_scope/predict_yamls/confg_prediction_green_yellowchannel.yaml',
    'blue': '/home/grunwaldlab/development/rna_scope/predict_yamls/config_prediction_dapi.yaml',
}


def find_h5_file() -> str:
    """Return the path to the main H5 file with experimental results.

    Returns:
        str: Path to the H5 file from results_config.py
    """
    return H5_FILE_PATH


def extract_slide_from_fov_key(fov_key: str) -> str:
    """
    Extract slide name from FOV key (e.g., 'q11110slidesno1june2025--m3a1--region003--313259--n0001' -> 'm3a1').
    """
    import re
    match = re.search(r'--([m]\d+[ab]\d+)--', fov_key.lower())
    if match:
        return match.group(1)
    return None


def load_slide_peak_intensities() -> dict:
    """
    Load pre-computed slide-specific peak intensities from CSV.
    This CSV is generated by fig_aggregate_scaling_v3.py and MUST exist.

    Returns dict: {(slide, channel): peak_intensity_photons}
    """
    if not PEAK_INTENSITIES_CSV.exists():
        raise FileNotFoundError(
            f"Peak intensities CSV not found at {PEAK_INTENSITIES_CSV}\n"
            f"Please run fig_aggregate_scaling_v3.py first to generate this file."
        )

    df = pd.read_csv(PEAK_INTENSITIES_CSV)
    peak_dict = {}
    for _, row in df.iterrows():
        slide = row['slide']
        channel = row['channel']
        peak_intensity = row['peak_intensity_photons']
        peak_dict[(slide, channel)] = peak_intensity

    print(f"Loaded {len(peak_dict)} slide-specific peak intensities from CSV")
    return peak_dict


# Global cache for slide peak intensities
_SLIDE_PEAK_INTENSITIES = None


def get_slide_peak_intensity(slide: str, channel: str) -> float:
    """
    Get pre-computed peak intensity for a slide/channel combination.
    Raises ValueError if not found (no fallback - data must exist).
    """
    global _SLIDE_PEAK_INTENSITIES
    if _SLIDE_PEAK_INTENSITIES is None:
        _SLIDE_PEAK_INTENSITIES = load_slide_peak_intensities()

    key = (slide, channel)
    if key not in _SLIDE_PEAK_INTENSITIES:
        raise ValueError(f"No peak intensity found for slide={slide}, channel={channel}")

    return _SLIDE_PEAK_INTENSITIES[key]


def load_photon_thresholds() -> dict:
    """
    Load negative control thresholds from CSV.
    Returns dict: {(slide, channel): threshold_photons}

    These are the 95th percentile of negative control signal, used to filter
    out clusters that are below the noise floor.
    """
    if not PHOTON_THRESHOLDS_CSV.exists():
        print(f"WARNING: Photon thresholds CSV not found at {PHOTON_THRESHOLDS_CSV}")
        return {}

    df = pd.read_csv(PHOTON_THRESHOLDS_CSV)
    thresh_dict = {}
    for _, row in df.iterrows():
        # Parse key like "('m3a1', 'green', None)"
        key_str = row['key']
        import ast
        try:
            key_tuple = ast.literal_eval(key_str)
            slide = key_tuple[0]
            channel = key_tuple[1]
            thresh_dict[(slide, channel)] = row['threshold']
        except:
            continue

    print(f"Loaded {len(thresh_dict)} slide-specific photon thresholds from CSV")
    return thresh_dict


# Global cache for photon thresholds
_PHOTON_THRESHOLDS = None


def get_photon_threshold(slide: str, channel: str) -> float:
    """
    Get negative control threshold for a slide/channel combination.
    Returns np.nan if not found.
    """
    global _PHOTON_THRESHOLDS
    if _PHOTON_THRESHOLDS is None:
        _PHOTON_THRESHOLDS = load_photon_thresholds()

    return _PHOTON_THRESHOLDS.get((slide, channel), np.nan)


def get_local_cfg():
    """Get config with local paths for model checkpoints."""
    cfg = {
        "bright_image_dir": 0.21,
        "dark_image_path": 101,
        "generate_plots": False,
        "num_channels": 4,
        "channel_map": {
            "blue": 0,
            "green": 1,
            "orange": 2,
            "red": 3
        },
        "roisize": 12,
        "iterations": 30,
        "dev": "cuda",
        "config_paths": LOCAL_YAML_PATHS,
    }
    return cfg


def get_color_config():
    """Get color configuration from results_config.py."""
    return CHANNEL_PARAMS


def get_detection_cfg():
    """Get detection configuration."""
    return {
        "uniform_filter1_size": 6,
        "uniform_filter2_size": 12,
        "local_max_filter_size": 9,
        "roisize": 12,
        "min_distance": 10,
    }


def get_fit_cfg():
    """Get fit configuration."""
    return {
        "zslices": 10,
        "bounds_mle_sigma": [[2, 10], [2, 10], [0, 30], [1, 1e9], [1, 1e6], [0.2, 4], [0.2, 4], [0.2, 10]],
        "bounds_mle": [[2, 10], [2, 10], [0, 30], [1, 1e9], [1, 1e6]],
        "iterations": 60,
        "damping_factor": 0.01,
        "initial_sigma": [187/162.5, 191/162.5, 592/500],
    }


def update_yaml_for_local(yaml_path: str, new_model_path: str):
    """
    Temporarily update the YAML config to use local paths.
    Returns the original config so it can be restored.
    """
    import yaml

    with open(yaml_path, 'r') as f:
        original_config = yaml.safe_load(f)

    # Create a copy with updated paths
    config = dict(original_config)
    config['model_path'] = new_model_path

    # Update loaders.test.file_paths to use a local temporary directory
    if 'loaders' in config and 'test' in config['loaders']:
        local_temp_dir = '/tmp/rna_scope_predict'
        os.makedirs(local_temp_dir, exist_ok=True)
        config['loaders'] = dict(config['loaders'])
        config['loaders']['test'] = dict(config['loaders']['test'])
        config['loaders']['test']['file_paths'] = [f'{local_temp_dir}/predict.h5']

    with open(yaml_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)

    return original_config


def restore_yaml_config(yaml_path: str, original_config: dict):
    """Restore the original YAML config."""
    import yaml

    with open(yaml_path, 'w') as f:
        yaml.dump(original_config, f, default_flow_style=False)


def get_npz_path_from_h5(fov_key: str, h5_path: str = None) -> str:
    """Get the NPZ file path for a FOV from H5 metadata."""
    import re

    if h5_path is None:
        h5_path = H5_FILE_PATH

    with h5py.File(h5_path, 'r') as f:
        if fov_key not in f:
            return None

        fov = f[fov_key]
        file_path = fov['general_metadata/file_path'][()]

        if isinstance(file_path, bytes):
            file_path = file_path.decode('utf-8')
        elif isinstance(file_path, np.ndarray):
            file_path = file_path.item() if file_path.size == 1 else str(file_path[0])
            if isinstance(file_path, bytes):
                file_path = file_path.decode('utf-8')

    # Check if file exists at stored path
    if Path(file_path).exists():
        return file_path

    local_base = '/media/grunwaldlab/SG Skyhawk AI 24TB/Q111 raw data'

    # Extract slide, region, and FOV from the path
    slide_match = re.search(r'(Slide M\d+ - [AB]\d+)', file_path)
    region_match = re.search(r'Region (\d+)', file_path)
    fov_match = re.search(r'FOV_(\d+)\.npz', file_path)

    if slide_match and region_match and fov_match:
        slide_name = slide_match.group(1)
        region_num = int(region_match.group(1))
        fov_num = int(fov_match.group(1))

        # Construct the filename
        region_dir = f'Region {region_num:03d}'
        region_dir_alt = f'Region {region_num}'
        filename = f'{slide_name}_Region_{region_num}_FOV_{fov_num}.npz'

        # Determine which dataset directories to search based on slide number
        # M1 slides: Q111_10slidesno2_june2025_new_illumination/exported/
        # M2 slides: Q111_15slidesno1_june2025/exported/
        # M3 slides: Q111_10slidesno1_june2025/.../exported/
        dataset_dirs = []
        if 'M1 -' in slide_name:
            dataset_dirs = [
                'Q111_10slidesno2_june2025_new_illumination/exported',
            ]
        elif 'M2 -' in slide_name:
            dataset_dirs = [
                'Q111_15slidesno1_june2025/exported',
            ]
        elif 'M3 -' in slide_name:
            dataset_dirs = [
                'Q111_10slidesno1_june2025/umcms-scope_grunwald-10slide-part-1_2025-06-26_2015/2025-06-24 11-41_annotated/exported',
            ]

        # Try each dataset directory
        for dataset_dir in dataset_dirs:
            # Try with leading zeros in region
            candidate = Path(local_base) / dataset_dir / slide_name / region_dir / filename
            if candidate.exists():
                return str(candidate)

            # Try without leading zeros
            candidate_alt = Path(local_base) / dataset_dir / slide_name / region_dir_alt / filename
            if candidate_alt.exists():
                return str(candidate_alt)

    return None


def load_npz_image(npz_path: str):
    """Load and decompress NPZ file."""
    with np.load(npz_path, allow_pickle=True) as data:
        compressed_data = data['compressed_data']
        metadata = data['metadata'].item()

    decompressed = blosc.decompress(compressed_data)
    dtype = np.dtype(metadata['dtype'])
    shape = tuple(metadata['shape'])
    arr = np.frombuffer(decompressed, dtype=dtype).reshape(shape)

    return arr, metadata


def process_channel_with_pruning(npz_path: str, channel: str, cfg: dict,
                                  color_cfg: dict, detection_cfg: dict, fit_cfg: dict,
                                  fov_key: str = None):
    """
    Process a channel using the full pipeline including spot detection and label pruning.

    This replicates the logic from main_one_folder.py including:
    - Label detection with UNet
    - Spot detection and fitting
    - break_sigma filtering
    - remove_labels_touching_spots

    Args:
        fov_key: FOV key from H5 file, used to look up slide-specific peak intensity

    Returns: (label_mask, spots_df, cluster_info)
    """
    yaml_path = LOCAL_YAML_PATHS[channel]
    original_config = update_yaml_for_local(yaml_path, LOCAL_MODEL_PATHS[channel])

    try:
        # Create RNAscope instance
        RS = RNAscopeclass(cfg)
        RS.compute_gain(images_max=1)
        RS.image_file = npz_path

        # Load image
        ch_index = color_cfg["channel_index"]
        image_data, channel_name = RS.load_image(npz_path, channel_to_load=ch_index)

        if image_data is None:
            print(f"  WARNING: Could not load {channel} channel")
            return None, pd.DataFrame(), None

        # Generate labels with UNet
        min_size = color_cfg['min_size']
        max_size = color_cfg['max_size']

        print(f"  Generating {channel} labels with UNet...")
        label_mask, label_image, label_sizes = RS.generate_label(
            min_size=min_size,
            max_size=max_size,
            mode=channel
        )

        print(f"  Initial clusters: {len(np.unique(label_mask)) - 1}")

        # Spot detection and fitting
        print(f"  Running spot detection...")
        (mu_fil, smp_fil, final_params, traces, mip_image,
         filtered_coords, z_starts, filt_indices, pfa_values, params_raw) = RS.detect_and_fit(
            detection_cfg, fit_cfg, image_data, color_cfg,
            label_mask=label_mask, batch_size=5000,
            fit_bg_per_slice=True
        )

        # Sigma-fitting pass
        print(f"  Running sigma fitting...")
        (mu_fil_sig, smp_fil_sig, final_params_sig, traces_sig, mip_image_sig,
         filtered_coords_sig, z_starts_sig, filt_indices_sig, pfa_values_sig, params_raw_sig) = RS.detect_and_fit(
            detection_cfg, fit_cfg, image_data, color_cfg,
            label_mask=label_mask, batch_size=5000,
            fit_bg_per_slice=True, fit_sigma=filt_indices
        )

        # Break filter and label pruning
        break_sigma = color_cfg.get('break_sigma')
        filter_on_break = None

        if break_sigma is not None and label_mask is not None and final_params_sig is not None:
            print(f"  Applying break_sigma filter...")
            filter_on_break = (
                (params_raw_sig[:, -3] < break_sigma[0]) &
                (params_raw_sig[:, -2] < break_sigma[1]) &
                (params_raw_sig[:, -1] < break_sigma[2])
            )
            final_filter = (filt_indices) & (filt_indices_sig) & (np.all(pfa_values <= 0.05, axis=1)) & (filter_on_break)

            # Remove labels touching final-filtered spots
            print(f"  Pruning labels touching spots...")
            _, pruned_mip, pruned = RS.remove_labels_touching_spots(
                filtered_coords_sig[final_filter, :], label_mask, dilation_radius=0
            )
            label_mask = pruned  # use pruned mask for downstream

        n_clusters = len(np.unique(label_mask)) - 1
        print(f"  Final clusters after pruning: {n_clusters}")

        # Convert image to photons for intensity calculation
        converted_image = RS.convert_to_photons(image_data)

        # Analyze cluster intensities (returns intensities, com_array, label_sizes, label_cvs)
        cluster_intensities, com_array, cluster_label_sizes, cluster_cvs = RS.analyze_label_intensitiesv2(label_mask, converted_image)

        # Get unique labels (excluding background) - these correspond to cluster_intensities array
        unique_labels = np.unique(label_mask)
        unique_labels = unique_labels[unique_labels > 0]

        # Create mapping from label_id to intensity/size index
        # analyze_label_intensitiesv2 returns intensities in order of unique_labels
        label_to_idx = {label_id: idx for idx, label_id in enumerate(unique_labels)}

        # Use label_sizes from analyze_label_intensitiesv2 (matches cluster_intensities indices)
        # Also keep bincount for any code that needs label_id-indexed sizes
        label_sizes_bincount = np.bincount(label_mask.ravel())  # Index 0 = background, index i = label i

        # Create spots DataFrame
        if final_params_sig is not None and filter_on_break is not None:
            final_filter = (filt_indices) & (filt_indices_sig) & (np.all(pfa_values <= 0.05, axis=1)) & (filter_on_break)
            spots_df = pd.DataFrame({
                'pos_x': filtered_coords_sig[final_filter, 1],
                'pos_y': filtered_coords_sig[final_filter, 0],
                'photons': params_raw_sig[final_filter, 3],
                'sigma_x': params_raw_sig[final_filter, 5],
                'sigma_y': params_raw_sig[final_filter, 6],
                'sigma_z': params_raw_sig[final_filter, 7],
            })
        else:
            spots_df = pd.DataFrame()

        print(f"  Final spots: {len(spots_df)}")

        # Get slide-specific peak intensity from pre-computed CSV (REQUIRED)
        # This CSV is generated by fig_aggregate_scaling_v3.py and must exist
        if fov_key is None:
            raise ValueError("fov_key is required for peak intensity lookup")

        slide = extract_slide_from_fov_key(fov_key)
        if slide is None:
            raise ValueError(f"Could not extract slide from fov_key: {fov_key}")

        peak_intensity = get_slide_peak_intensity(slide, channel)
        print(f"  Using slide-specific peak intensity for {slide}/{channel}: {peak_intensity:.2f} photons")

        # Cluster info - store raw intensities and peak for mRNA equiv calculation
        # Include label_to_idx mapping so we can look up intensity by label_id
        cluster_info = {
            'intensities': cluster_intensities,  # Raw photon sums per cluster (indexed by label_to_idx)
            'cvs': cluster_cvs,  # CV values per cluster (indexed by label_to_idx)
            'sizes': label_sizes_bincount,  # Sizes indexed directly by label_id
            'coms': com_array,
            'peak_intensity': peak_intensity,  # For mRNA equiv = intensity / peak
            'label_to_idx': label_to_idx,  # Mapping from label_id to intensities array index
        }

        return label_mask, spots_df, cluster_info

    finally:
        restore_yaml_config(yaml_path, original_config)


def create_mip(image_3d: np.ndarray) -> np.ndarray:
    """Create maximum intensity projection."""
    return np.max(image_3d, axis=0)


def normalize_to_8bit(image: np.ndarray, pmin: float = 1, pmax: float = 99.5) -> np.ndarray:
    """Normalize image to 8-bit using percentile-based contrast."""
    vmin = np.percentile(image, pmin)
    vmax = np.percentile(image, pmax)
    normalized = (image.astype(np.float32) - vmin) / (vmax - vmin + 1e-10)
    normalized = np.clip(normalized, 0, 1)
    return (normalized * 255).astype(np.uint8)


def create_colored_image(mip_8bit: np.ndarray, channel: str) -> np.ndarray:
    """Create grayscale RGB image from grayscale MIP.

    All channels output as grayscale (R=G=B) for print publication.
    The channel parameter is kept for API compatibility but ignored.
    """
    rgb = np.zeros((*mip_8bit.shape, 3), dtype=np.uint8)

    # All channels rendered as grayscale (R=G=B)
    rgb[:, :, 0] = mip_8bit
    rgb[:, :, 1] = mip_8bit
    rgb[:, :, 2] = mip_8bit

    return rgb


def draw_cluster_contours(image_rgb: np.ndarray, label_mask_mip: np.ndarray,
                          color: tuple = (255, 255, 255), thickness: int = 1):
    """Draw cluster contours on RGB image."""
    img = Image.fromarray(image_rgb)
    draw = ImageDraw.Draw(img)

    unique_labels = np.unique(label_mask_mip)
    unique_labels = unique_labels[unique_labels > 0]

    for label_id in unique_labels:
        binary_mask = (label_mask_mip == label_id).astype(np.uint8)
        contours = measure.find_contours(binary_mask, 0.5)

        for contour in contours:
            points = [(int(p[1]), int(p[0])) for p in contour]
            if len(points) > 2:
                draw.line(points + [points[0]], fill=color, width=thickness)

    return np.array(img)


def draw_spots(image_rgb: np.ndarray, spots_df: pd.DataFrame,
               color: tuple = (255, 255, 255), radius: int = 2):
    """Draw spot markers on RGB image."""
    img = Image.fromarray(image_rgb)
    draw = ImageDraw.Draw(img)

    for _, row in spots_df.iterrows():
        x, y = int(row['pos_x']), int(row['pos_y'])
        draw.ellipse([x - radius, y - radius, x + radius, y + radius],
                     outline=color, width=1)

    return np.array(img)


def draw_scale_bar(image_rgb: np.ndarray, scale_um: float = 50,
                   pixel_size: float = PIXEL_SIZE_XY,
                   position: str = 'bottom_right',
                   color: tuple = (255, 255, 255),
                   thickness: int = 4,
                   margin: int = 20):
    """Draw scale bar on image."""
    img = Image.fromarray(image_rgb)
    draw = ImageDraw.Draw(img)

    bar_length_px = int(scale_um / pixel_size)

    h, w = image_rgb.shape[:2]

    if position == 'bottom_right':
        x_end = w - margin
        x_start = x_end - bar_length_px
        y = h - margin
    elif position == 'bottom_left':
        x_start = margin
        x_end = x_start + bar_length_px
        y = h - margin

    draw.line([(x_start, y), (x_end, y)], fill=color, width=thickness)

    return np.array(img)


def draw_legend(image_rgb: np.ndarray, channel: str,
                position: str = 'top_left', margin: int = 15):
    """
    Draw a legend showing spot and cluster symbols.

    Args:
        image_rgb: RGB image array
        channel: 'green' or 'orange' (determines cluster contour color)
        position: 'top_left' or 'top_right'
        margin: margin from edge in pixels

    Returns:
        Image with legend drawn
    """
    img = Image.fromarray(image_rgb)
    draw = ImageDraw.Draw(img)

    h, w = image_rgb.shape[:2]

    # Legend box dimensions
    box_width = 120
    box_height = 50
    padding = 8

    # Position
    if position == 'top_left':
        x_start = margin
        y_start = margin
    else:  # top_right
        x_start = w - margin - box_width
        y_start = margin

    # Draw semi-transparent background box
    box_color = (40, 40, 40)  # Dark gray
    draw.rectangle([x_start, y_start, x_start + box_width, y_start + box_height],
                   fill=box_color, outline=(100, 100, 100))

    # Spot symbol: white circle
    spot_x = x_start + padding + 5
    spot_y = y_start + padding + 8
    spot_radius = 3
    draw.ellipse([spot_x - spot_radius, spot_y - spot_radius,
                  spot_x + spot_radius, spot_y + spot_radius],
                 fill=(255, 255, 255), outline=(255, 255, 255))

    # Spot label
    draw.text((spot_x + 12, spot_y - 6), "Single mRNA", fill=(255, 255, 255))

    # Cluster symbol: colored contour rectangle
    cluster_x = x_start + padding + 5
    cluster_y = y_start + padding + 28
    cluster_size = 8
    cluster_color = (0, 255, 0) if channel == 'green' else (255, 165, 0)
    draw.rectangle([cluster_x - cluster_size//2, cluster_y - cluster_size//2,
                    cluster_x + cluster_size//2, cluster_y + cluster_size//2],
                   outline=cluster_color, width=2)

    # Cluster label
    draw.text((cluster_x + 12, cluster_y - 6), "Cluster", fill=(255, 255, 255))

    return np.array(img)


def find_good_zoom_regions(label_mask_mip: np.ndarray, cluster_info: dict,
                           n_regions: int = 3, zoom_size: int = ZOOM_SIZE, seed: int = 42):
    """
    Find good zoom regions that contain clusters with varying sizes/intensities.

    Args:
        label_mask_mip: 2D label mask (MIP)
        cluster_info: dict with cluster information
        n_regions: Number of zoom regions to find
        zoom_size: Size of zoom region in pixels
        seed: Random seed for reproducibility

    Returns list of (center_x, center_y) tuples.
    """
    np.random.seed(seed)  # Set seed for reproducible selection
    h, w = label_mask_mip.shape

    # Get cluster properties
    props = regionprops(label_mask_mip)

    if len(props) < 3:
        # Just return center of image
        return [(w // 2, h // 2)]

    # Score each potential region by cluster diversity
    margin = zoom_size // 2 + 10

    regions = []
    for prop in props:
        cy, cx = prop.centroid
        cx, cy = int(cx), int(cy)

        # Check bounds
        if cx < margin or cx > w - margin or cy < margin or cy > h - margin:
            continue

        # Count clusters in this region
        x_start = cx - zoom_size // 2
        x_end = cx + zoom_size // 2
        y_start = cy - zoom_size // 2
        y_end = cy + zoom_size // 2

        region_mask = label_mask_mip[y_start:y_end, x_start:x_end]
        labels_in_region = np.unique(region_mask)
        labels_in_region = labels_in_region[labels_in_region > 0]
        n_clusters = len(labels_in_region)

        if n_clusters >= 3:  # Want regions with multiple clusters
            regions.append((cx, cy, n_clusters))

    if not regions:
        return [(w // 2, h // 2)]

    # Sort by cluster count and pick diverse locations
    regions.sort(key=lambda x: -x[2])

    # Select regions that are spatially separated
    selected = []
    min_dist = zoom_size * 1.5

    for cx, cy, n in regions:
        too_close = False
        for sx, sy in selected:
            if np.sqrt((cx - sx)**2 + (cy - sy)**2) < min_dist:
                too_close = True
                break
        if not too_close:
            selected.append((cx, cy))
            if len(selected) >= n_regions:
                break

    return selected if selected else [(w // 2, h // 2)]


def create_zoom_with_colorbar(image_3d: np.ndarray, label_mask: np.ndarray,
                              cluster_info: dict, spots_df: pd.DataFrame,
                              center_x: int, center_y: int,
                              zoom_size: int, channel: str, color_by: str = 'intensity',
                              output_path: Path = None, vmin: float = None, vmax: float = None):
    """
    Create zoomed image with clusters colored by intensity or size, including spots.

    Args:
        image_3d: 3D image (z, y, x)
        label_mask: 3D label mask
        cluster_info: dict with 'intensities', 'sizes', and 'peak_intensity'
        spots_df: DataFrame with spot positions ('pos_x', 'pos_y')
        center_x, center_y: zoom center
        zoom_size: size of zoom region
        channel: 'green' or 'orange'
        color_by: 'intensity' (mRNA equiv.) or 'size' (µm³)
        output_path: where to save (SVG format)
        vmin, vmax: colorbar range (auto if None)
    """
    # Extract zoom region
    h, w = image_3d.shape[1], image_3d.shape[2]
    x_start = max(0, center_x - zoom_size // 2)
    x_end = min(w, center_x + zoom_size // 2)
    y_start = max(0, center_y - zoom_size // 2)
    y_end = min(h, center_y + zoom_size // 2)

    # MIP of zoom region
    mip_zoom = np.max(image_3d[:, y_start:y_end, x_start:x_end], axis=0)
    label_mip_zoom = np.max(label_mask[:, y_start:y_end, x_start:x_end], axis=0)

    # Normalize background image (use same settings as overview images for consistency)
    mip_8bit = normalize_to_8bit(mip_zoom)

    # Create base colored image (same brightness as raw images)
    base_rgb = create_colored_image(mip_8bit, channel)

    # Get values for coloring
    unique_labels = np.unique(label_mip_zoom)
    unique_labels = unique_labels[unique_labels > 0]

    if len(unique_labels) == 0:
        print(f"    No clusters in zoom region")
        return None

    # Get peak intensity for mRNA equivalent calculation
    peak_intensity = cluster_info.get('peak_intensity', np.nan)

    # Get threshold for cluster filtering (from H5 data or use default)
    # Default: cluster must have at least 2 mRNA equivalents (intensity > 2 * peak)
    threshold = cluster_info.get('threshold', None)
    if threshold is None and not np.isnan(peak_intensity):
        threshold = 2.0 * peak_intensity  # minimum 2 mRNA equivalent

    # Map label IDs to values
    intensities = cluster_info['intensities']
    cvs = cluster_info.get('cvs', None)
    sizes = cluster_info['sizes']
    label_to_idx = cluster_info.get('label_to_idx', {})

    label_values = {}
    for label_id in unique_labels:
        # Use label_to_idx mapping to get correct intensity index
        if label_id not in label_to_idx:
            continue
        idx = label_to_idx[label_id]
        if idx < len(intensities):
            raw_intensity = intensities[idx]

            # Apply threshold filtering (same as comprehensive_cortex_striatum_analysis_v2.py)
            if threshold is not None and raw_intensity <= threshold:
                continue  # Skip clusters below threshold

            # Apply CV filtering (CV >= CV_THRESHOLD means good quality)
            if cvs is not None and idx < len(cvs) and cvs[idx] < CV_THRESHOLD:
                continue  # Skip clusters with low CV (poor quality)

            if color_by == 'intensity':
                # Convert to mRNA equivalents: intensity / peak_intensity
                # Same logic as comprehensive_cortex_striatum_analysis_v2.py
                if not np.isnan(peak_intensity) and peak_intensity > 0:
                    label_values[label_id] = raw_intensity / peak_intensity
                else:
                    # Fallback if no peak available (shouldn't happen)
                    label_values[label_id] = raw_intensity / 1000  # rough estimate
            else:  # size
                # For sizes, use label_id directly since sizes comes from bincount
                if label_id < len(sizes):
                    label_values[label_id] = sizes[label_id] * VOXEL_VOLUME_UM3  # Convert to µm³
                else:
                    label_values[label_id] = 0

    if not label_values:
        return None

    values = list(label_values.values())

    # Set colorbar range
    if vmin is None:
        vmin = np.percentile(values, 5)
    if vmax is None:
        vmax = np.percentile(values, 95)

    # Use colormap
    if color_by == 'intensity':
        cmap = plt.colormaps['viridis']
    else:
        cmap = plt.colormaps['plasma']

    norm = Normalize(vmin=vmin, vmax=vmax)

    # Color each cluster
    overlay_rgb = base_rgb.copy()

    for label_id, value in label_values.items():
        mask = (label_mip_zoom == label_id)
        color = cmap(norm(value))[:3]  # RGB 0-1
        color_255 = tuple(int(c * 255) for c in color)

        # Fill cluster region with color
        overlay_rgb[mask, 0] = color_255[0]
        overlay_rgb[mask, 1] = color_255[1]
        overlay_rgb[mask, 2] = color_255[2]

    # Create figure with colorbar
    fig, (ax_cbar, ax_img) = plt.subplots(2, 1, figsize=(3.5, 4.0),
                                           gridspec_kw={'height_ratios': [1, 12]})

    ax_img.imshow(overlay_rgb)
    ax_img.axis('off')

    # Add spots to the zoom region
    if spots_df is not None and len(spots_df) > 0:
        # Filter spots within zoom region
        spots_in_zoom = spots_df[
            (spots_df['pos_x'] >= x_start) & (spots_df['pos_x'] < x_end) &
            (spots_df['pos_y'] >= y_start) & (spots_df['pos_y'] < y_end)
        ].copy()

        if len(spots_in_zoom) > 0:
            # Convert to local coordinates
            local_x = spots_in_zoom['pos_x'].values - x_start
            local_y = spots_in_zoom['pos_y'].values - y_start

            # Draw spots as small white circles
            ax_img.scatter(local_x, local_y, s=4, c='white', marker='o',
                          edgecolors='none', alpha=0.8, linewidths=0)

    # Scale bar
    scale_bar_px = int(SCALE_BAR_ZOOM / PIXEL_SIZE_XY)
    ax_img.plot([zoom_size - 15 - scale_bar_px, zoom_size - 15],
                [zoom_size - 10, zoom_size - 10], 'w-', linewidth=3)
    ax_img.text(zoom_size - 15 - scale_bar_px/2, zoom_size - 18,
                f'{SCALE_BAR_ZOOM} µm', color='white', fontsize=8, ha='center')

    # Colorbar
    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=ax_cbar, orientation='horizontal')
    ax_cbar.xaxis.set_ticks_position('top')
    ax_cbar.xaxis.set_label_position('top')

    # Set tick labels with proper formatting
    if color_by == 'intensity':
        cbar.set_label('Cluster intensity (mRNA equiv.)', fontsize=9, color='white')
        # Format mRNA equivalent values (typically 10-1000 range)
        cbar.set_ticks([vmin, (vmin + vmax) / 2, vmax])
        if vmax >= 100:
            cbar.set_ticklabels([f'{vmin:.0f}', f'{(vmin+vmax)/2:.0f}', f'{vmax:.0f}'])
        else:
            cbar.set_ticklabels([f'{vmin:.1f}', f'{(vmin+vmax)/2:.1f}', f'{vmax:.1f}'])
    else:
        cbar.set_label('Cluster volume (µm³)', fontsize=9, color='white')
        # Format size values
        cbar.set_ticks([vmin, (vmin + vmax) / 2, vmax])
        cbar.set_ticklabels([f'{vmin:.1f}', f'{(vmin+vmax)/2:.1f}', f'{vmax:.1f}'])

    # Make tick labels visible on black background
    cbar.ax.tick_params(colors='white', labelsize=7)

    plt.tight_layout()

    if output_path:
        # Save as SVG format
        output_path = Path(output_path)
        svg_path = output_path.with_suffix('.svg')
        fig.savefig(svg_path, format='svg', bbox_inches='tight', facecolor='black')
        plt.close(fig)
        return str(svg_path)
    else:
        plt.close(fig)
        return overlay_rgb


def create_clean_zoom(image_3d: np.ndarray, spots_df: pd.DataFrame,
                      center_x: int, center_y: int, zoom_size: int, channel: str,
                      output_path: Path = None):
    """
    Create clean zoomed image showing only raw image and spots (no cluster labels).

    Args:
        image_3d: 3D image (z, y, x)
        spots_df: DataFrame with spot positions ('pos_x', 'pos_y')
        center_x, center_y: zoom center
        zoom_size: size of zoom region
        channel: 'green' or 'orange'
        output_path: where to save (SVG format)
    """
    # Extract zoom region
    h, w = image_3d.shape[1], image_3d.shape[2]
    x_start = max(0, center_x - zoom_size // 2)
    x_end = min(w, center_x + zoom_size // 2)
    y_start = max(0, center_y - zoom_size // 2)
    y_end = min(h, center_y + zoom_size // 2)

    # MIP of zoom region
    mip_zoom = np.max(image_3d[:, y_start:y_end, x_start:x_end], axis=0)

    # Normalize background image (use same settings as overview images for consistency)
    mip_8bit = normalize_to_8bit(mip_zoom)

    # Create base colored image (same as overview images)
    base_rgb = create_colored_image(mip_8bit, channel)

    # Create figure
    fig, ax = plt.subplots(1, 1, figsize=(3.5, 3.5))

    ax.imshow(base_rgb)
    ax.axis('off')

    # Add spots to the zoom region
    if spots_df is not None and len(spots_df) > 0:
        # Filter spots within zoom region
        spots_in_zoom = spots_df[
            (spots_df['pos_x'] >= x_start) & (spots_df['pos_x'] < x_end) &
            (spots_df['pos_y'] >= y_start) & (spots_df['pos_y'] < y_end)
        ].copy()

        if len(spots_in_zoom) > 0:
            # Convert to local coordinates
            local_x = spots_in_zoom['pos_x'].values - x_start
            local_y = spots_in_zoom['pos_y'].values - y_start

            # Draw spots as small white circles
            ax.scatter(local_x, local_y, s=4, c='white', marker='o',
                      edgecolors='none', alpha=0.8, linewidths=0)

    # Scale bar
    scale_bar_px = int(SCALE_BAR_ZOOM / PIXEL_SIZE_XY)
    ax.plot([zoom_size - 15 - scale_bar_px, zoom_size - 15],
            [zoom_size - 10, zoom_size - 10], 'w-', linewidth=3)
    ax.text(zoom_size - 15 - scale_bar_px/2, zoom_size - 18,
            f'{SCALE_BAR_ZOOM} µm', color='white', fontsize=8, ha='center')

    plt.tight_layout()

    if output_path:
        # Save as SVG format
        output_path = Path(output_path)
        svg_path = output_path.with_suffix('.svg')
        fig.savefig(svg_path, format='svg', bbox_inches='tight', facecolor='black')
        plt.close(fig)
        return str(svg_path)
    else:
        plt.close(fig)
        return base_rgb


def save_zoom_images(image_3d: np.ndarray, label_mask: np.ndarray,
                     cluster_info: dict, spots_df: pd.DataFrame,
                     channel: str, output_dir: Path, n_zooms: int = 5,
                     zoom_size: int = ZOOM_SIZE, slide: str = None,
                     vmin_int: float = None, vmax_int: float = None,
                     vmin_vol: float = None, vmax_vol: float = None):
    """
    Find and save multiple zoomed images in 4 styles (same layout as overview_spots_clusters.tif):
    1. Clean - raw image + scale bar only
    2. Spots+clusters - raw image + cluster contours + spots + scale bar
    3. Intensity - clusters filled with intensity colormap + spots + scale bar
    4. Volume - clusters filled with volume colormap + spots + scale bar

    Args:
        image_3d: 3D image (z, y, x)
        label_mask: 3D label mask
        cluster_info: dict with 'intensities', 'sizes', and 'peak_intensity'
        spots_df: DataFrame with spot positions
        channel: 'green' or 'orange'
        output_dir: directory to save zoom images
        n_zooms: number of zoom regions to save (default 5)
        zoom_size: size of zoom region in pixels (default ZOOM_SIZE)
        slide: slide name for threshold lookup
        vmin_int, vmax_int: colorbar range for intensity
        vmin_vol, vmax_vol: colorbar range for volume

    Returns:
        Tuple of (saved_paths dict, zoom_centers list)
    """
    # Create zoom subdirectories
    zoom_clean_dir = output_dir / 'zooms_clean'
    zoom_spots_dir = output_dir / 'zooms_spots_clusters'
    zoom_int_dir = output_dir / 'zooms_intensity'
    zoom_vol_dir = output_dir / 'zooms_volume'

    for d in [zoom_clean_dir, zoom_spots_dir, zoom_int_dir, zoom_vol_dir]:
        d.mkdir(exist_ok=True)

    # Get label MIP for finding good regions
    label_mip = np.max(label_mask, axis=0)

    # Find good zoom regions (more than requested to have options)
    zoom_centers = find_good_zoom_regions(label_mip, cluster_info,
                                          n_regions=n_zooms * 2,
                                          zoom_size=zoom_size)

    # Limit to requested number
    zoom_centers = zoom_centers[:n_zooms]

    saved_paths = {'clean': [], 'spots_clusters': [], 'intensity': [], 'volume': []}
    h, w = image_3d.shape[1], image_3d.shape[2]

    # Get threshold for cluster filtering
    peak_intensity = cluster_info.get('peak_intensity', np.nan)
    threshold = cluster_info.get('threshold', None)
    if threshold is None and not np.isnan(peak_intensity):
        threshold = 2.0 * peak_intensity

    intensities = cluster_info['intensities']
    cvs = cluster_info.get('cvs', None)
    sizes = cluster_info['sizes']
    label_to_idx = cluster_info.get('label_to_idx', {})

    # Compute values for colormaps
    if not np.isnan(peak_intensity) and peak_intensity > 0:
        intensity_values = intensities / peak_intensity  # mRNA equivalents
    else:
        intensity_values = intensities / 1000
    volume_values = sizes * VOXEL_VOLUME_UM3  # µm³

    # Auto-determine colorbar ranges if not provided
    if vmin_int is None:
        vmin_int = np.percentile(intensity_values[intensity_values > 0], 5) if len(intensity_values) > 0 else 0
    if vmax_int is None:
        vmax_int = np.percentile(intensity_values, 95) if len(intensity_values) > 0 else 100
    if vmin_vol is None:
        vmin_vol = np.percentile(volume_values[volume_values > 0], 5) if len(volume_values) > 0 else 0
    if vmax_vol is None:
        vmax_vol = np.percentile(volume_values, 95) if len(volume_values) > 0 else 30

    norm_int = Normalize(vmin=vmin_int, vmax=vmax_int)
    norm_vol = Normalize(vmin=vmin_vol, vmax=vmax_vol)
    cmap_int = cm.plasma
    cmap_vol = cm.viridis

    # Cluster contour color (same as overview_spots_clusters.tif)
    cluster_color = (0, 255, 0) if channel == 'green' else (255, 165, 0)

    for i, (cx, cy) in enumerate(zoom_centers):
        # Extract zoom region bounds
        x_start = max(0, cx - zoom_size // 2)
        x_end = min(w, cx + zoom_size // 2)
        y_start = max(0, cy - zoom_size // 2)
        y_end = min(h, cy + zoom_size // 2)

        actual_w = x_end - x_start
        actual_h = y_end - y_start

        # MIP of zoom region
        mip_zoom = np.max(image_3d[:, y_start:y_end, x_start:x_end], axis=0)
        label_mip_zoom = np.max(label_mask[:, y_start:y_end, x_start:x_end], axis=0)

        # Normalize image (use same settings as overview images for consistency)
        mip_8bit = normalize_to_8bit(mip_zoom)

        # Create base colored image (full brightness)
        base_rgb = create_colored_image(mip_8bit, channel)

        # Get spots in this zoom region
        spots_in_zoom = None
        if spots_df is not None and len(spots_df) > 0:
            spots_in_zoom = spots_df[
                (spots_df['pos_x'] >= x_start) & (spots_df['pos_x'] < x_end) &
                (spots_df['pos_y'] >= y_start) & (spots_df['pos_y'] < y_end)
            ].copy()
            # Convert to local coordinates
            spots_in_zoom['pos_x'] = spots_in_zoom['pos_x'] - x_start
            spots_in_zoom['pos_y'] = spots_in_zoom['pos_y'] - y_start

        # =====================================================================
        # 1. CLEAN ZOOM - raw image + scale bar only
        # =====================================================================
        clean_rgb = base_rgb.copy()
        clean_rgb = draw_scale_bar(clean_rgb, scale_um=SCALE_BAR_ZOOM,
                                   position='bottom_right', thickness=3, margin=15)
        zoom_path = zoom_clean_dir / f'zoom_{i+1:02d}_clean.tif'
        imwrite(zoom_path, clean_rgb)
        saved_paths['clean'].append(zoom_path)

        # =====================================================================
        # 2. SPOTS+CLUSTERS ZOOM - same style as overview_spots_clusters.tif
        # =====================================================================
        spots_clusters_rgb = base_rgb.copy()

        # Draw cluster contours (using same function as overview)
        spots_clusters_rgb = draw_cluster_contours(spots_clusters_rgb, label_mip_zoom,
                                                    color=cluster_color, thickness=2)

        # Draw spots
        if spots_in_zoom is not None and len(spots_in_zoom) > 0:
            spots_clusters_rgb = draw_spots(spots_clusters_rgb, spots_in_zoom,
                                            color=(255, 255, 255), radius=2)

        # Add scale bar
        spots_clusters_rgb = draw_scale_bar(spots_clusters_rgb, scale_um=SCALE_BAR_ZOOM,
                                            position='bottom_right', thickness=3, margin=15)
        zoom_path = zoom_spots_dir / f'zoom_{i+1:02d}_spots_clusters.tif'
        imwrite(zoom_path, spots_clusters_rgb)
        saved_paths['spots_clusters'].append(zoom_path)

        # =====================================================================
        # 3. INTENSITY ZOOM - clusters filled with intensity colormap
        # =====================================================================
        # Use same base image brightness as clean zoom for consistency
        int_rgb = base_rgb.copy()

        # Fill clusters with intensity colors
        unique_labels = np.unique(label_mip_zoom)
        unique_labels = unique_labels[unique_labels > 0]

        for label_id in unique_labels:
            # Use label_to_idx mapping to get correct intensity index
            if label_id not in label_to_idx:
                continue
            idx = label_to_idx[label_id]
            if idx < len(intensities):
                # Apply threshold filter
                if threshold is not None and intensities[idx] <= threshold:
                    continue
                # Apply CV filtering (CV >= CV_THRESHOLD means good quality)
                if cvs is not None and idx < len(cvs) and cvs[idx] < CV_THRESHOLD:
                    continue  # Skip clusters with low CV (poor quality)
                if idx < len(intensity_values):
                    value = intensity_values[idx]
                    rgba = cmap_int(norm_int(value))
                    color = (int(rgba[0] * 255), int(rgba[1] * 255), int(rgba[2] * 255))
                    mask = label_mip_zoom == label_id
                    int_rgb[mask] = color

        # Draw spots
        if spots_in_zoom is not None and len(spots_in_zoom) > 0:
            int_rgb = draw_spots(int_rgb, spots_in_zoom, color=(255, 255, 255), radius=2)

        # Add scale bar
        int_rgb = draw_scale_bar(int_rgb, scale_um=SCALE_BAR_ZOOM,
                                 position='bottom_right', thickness=3, margin=15)
        zoom_path = zoom_int_dir / f'zoom_{i+1:02d}_intensity.tif'
        imwrite(zoom_path, int_rgb)
        saved_paths['intensity'].append(zoom_path)

        # =====================================================================
        # 4. VOLUME ZOOM - clusters filled with volume colormap
        # =====================================================================
        # Use same base image brightness as clean zoom for consistency
        vol_rgb = base_rgb.copy()

        # Fill clusters with volume colors
        for label_id in unique_labels:
            # Use label_to_idx mapping to get correct intensity index
            if label_id not in label_to_idx:
                continue
            idx = label_to_idx[label_id]
            if idx < len(intensities):
                # Apply threshold filter
                if threshold is not None and intensities[idx] <= threshold:
                    continue
                # Apply CV filtering (CV >= CV_THRESHOLD means good quality)
                if cvs is not None and idx < len(cvs) and cvs[idx] < CV_THRESHOLD:
                    continue  # Skip clusters with low CV (poor quality)
                # For sizes, use label_id directly since sizes comes from bincount
                if label_id < len(sizes):
                    value = sizes[label_id] * VOXEL_VOLUME_UM3
                    rgba = cmap_vol(norm_vol(value))
                    color = (int(rgba[0] * 255), int(rgba[1] * 255), int(rgba[2] * 255))
                    mask = label_mip_zoom == label_id
                    vol_rgb[mask] = color

        # Draw spots
        if spots_in_zoom is not None and len(spots_in_zoom) > 0:
            vol_rgb = draw_spots(vol_rgb, spots_in_zoom, color=(255, 255, 255), radius=2)

        # Add scale bar
        vol_rgb = draw_scale_bar(vol_rgb, scale_um=SCALE_BAR_ZOOM,
                                 position='bottom_right', thickness=3, margin=15)
        zoom_path = zoom_vol_dir / f'zoom_{i+1:02d}_volume.tif'
        imwrite(zoom_path, vol_rgb)
        saved_paths['volume'].append(zoom_path)

        # Save zoom metadata
        # Count clusters passing both threshold and CV filters
        def passes_filters(label_id):
            if label_id not in label_to_idx:
                return False
            idx = label_to_idx[label_id]
            if idx >= len(intensities):
                return False
            if threshold is not None and intensities[idx] <= threshold:
                return False
            if cvs is not None and idx < len(cvs) and cvs[idx] < CV_THRESHOLD:
                return False
            return True
        n_clusters_in_zoom = len([l for l in unique_labels if passes_filters(l)])

        with open(zoom_spots_dir / f'zoom_{i+1:02d}_info.txt', 'w') as f:
            f.write(f"Zoom region {i+1}\n")
            f.write(f"Center: ({cx}, {cy})\n")
            f.write(f"Bounds: x=[{x_start}, {x_end}], y=[{y_start}, {y_end}]\n")
            f.write(f"Size: {actual_w} x {actual_h} pixels\n")
            f.write(f"Size: {actual_w * PIXEL_SIZE_XY:.1f} x {actual_h * PIXEL_SIZE_XY:.1f} µm\n")
            f.write(f"Scale bar: {SCALE_BAR_ZOOM} µm\n")
            f.write(f"Clusters in region: {n_clusters_in_zoom}\n")

    # Save colorbars
    # Intensity colorbar
    fig, ax = plt.subplots(figsize=(0.3, 3))
    cb = plt.colorbar(cm.ScalarMappable(norm=norm_int, cmap=cmap_int), cax=ax)
    cb.set_label('mRNA equiv.', fontsize=8)
    cb.ax.tick_params(labelsize=7)
    fig.savefig(zoom_int_dir / 'colorbar_intensity.svg', format='svg', bbox_inches='tight', transparent=True)
    plt.close(fig)

    # Volume colorbar
    fig, ax = plt.subplots(figsize=(0.3, 3))
    cb = plt.colorbar(cm.ScalarMappable(norm=norm_vol, cmap=cmap_vol), cax=ax)
    cb.set_label('µm³', fontsize=8)
    cb.ax.tick_params(labelsize=7)
    fig.savefig(zoom_vol_dir / 'colorbar_volume.svg', format='svg', bbox_inches='tight', transparent=True)
    plt.close(fig)

    print(f"  Saved {n_zooms} zoom images x 4 styles to {output_dir}")
    return saved_paths, zoom_centers


def save_overview_image(image_3d: np.ndarray, label_mask: np.ndarray,
                        spots_df: pd.DataFrame, channel: str,
                        output_path: Path, zoom_regions: list = None):
    """Save overview image with spots, clusters, and zoom region indicators."""
    mip = create_mip(image_3d)
    mip_8bit = normalize_to_8bit(mip)
    colored_img = create_colored_image(mip_8bit, channel)

    label_mip = np.max(label_mask, axis=0)

    # Draw clusters
    cluster_color = (0, 255, 0) if channel == 'green' else (255, 165, 0)
    img_with_both = draw_cluster_contours(colored_img.copy(), label_mip,
                                           color=cluster_color, thickness=2)

    # Draw spots
    if len(spots_df) > 0:
        img_with_both = draw_spots(img_with_both, spots_df,
                                   color=(255, 255, 255), radius=2)

    # Draw zoom region boxes
    if zoom_regions:
        img = Image.fromarray(img_with_both)
        draw = ImageDraw.Draw(img)
        colors = [(255, 255, 0), (0, 255, 255), (255, 0, 255)]  # Yellow, cyan, magenta

        for i, (cx, cy) in enumerate(zoom_regions):
            color = colors[i % len(colors)]
            x1 = cx - ZOOM_SIZE // 2
            y1 = cy - ZOOM_SIZE // 2
            x2 = cx + ZOOM_SIZE // 2
            y2 = cy + ZOOM_SIZE // 2
            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)

        img_with_both = np.array(img)

    # Add scale bar
    img_with_both = draw_scale_bar(img_with_both, scale_um=50)

    # Add legend showing spot and cluster symbols
    img_with_both = draw_legend(img_with_both, channel, position='top_left')

    imwrite(output_path, img_with_both)
    return img_with_both


def save_clean_overview(image_3d: np.ndarray, channel: str, output_path: Path):
    """Save clean overview image - just the raw MIP with no labels, spots, or annotations."""
    mip = create_mip(image_3d)
    mip_8bit = normalize_to_8bit(mip)
    colored_img = create_colored_image(mip_8bit, channel)

    # Add scale bar only
    img_with_scale = draw_scale_bar(colored_img, scale_um=50)

    imwrite(output_path, img_with_scale)
    return img_with_scale


def save_overview_threshold_filter(image_3d: np.ndarray, label_mask: np.ndarray,
                                    cluster_info: dict, spots_df: pd.DataFrame,
                                    channel: str, output_path: Path, slide: str = None):
    """
    Save overview showing which clusters passed/failed the negative control threshold.

    - Green/cyan contours: clusters that PASSED the threshold (real signal)
    - Red contours: clusters that FAILED the threshold (below noise floor)

    Args:
        image_3d: 3D image (z, y, x)
        label_mask: 3D label mask
        cluster_info: dict with 'intensities', 'sizes', 'peak_intensity', 'label_to_idx'
        spots_df: DataFrame with spot positions
        channel: 'green' or 'orange'
        output_path: where to save (TIFF)
        slide: slide name for negative control threshold lookup
    """
    mip = create_mip(image_3d)
    mip_8bit = normalize_to_8bit(mip)
    colored_img = create_colored_image(mip_8bit, channel)
    label_mip = np.max(label_mask, axis=0)

    # Get cluster info
    unique_labels = np.unique(label_mip)
    unique_labels = unique_labels[unique_labels > 0]

    intensities = cluster_info['intensities']
    cvs = cluster_info.get('cvs', None)
    label_to_idx = cluster_info.get('label_to_idx', {})

    # Get negative control threshold
    threshold = None
    if slide is not None:
        threshold = get_photon_threshold(slide, channel)
        if np.isnan(threshold):
            threshold = None

    # Separate passed and failed labels
    passed_labels = []
    failed_labels = []

    for label_id in unique_labels:
        if label_id not in label_to_idx:
            continue
        idx = label_to_idx[label_id]
        if idx >= len(intensities):
            continue

        raw_intensity = intensities[idx]

        # Skip clusters with low CV (CV >= CV_THRESHOLD means good quality)
        if cvs is not None and idx < len(cvs) and cvs[idx] < CV_THRESHOLD:
            continue  # Don't show clusters with low CV

        if threshold is not None and raw_intensity <= threshold:
            failed_labels.append(label_id)
        else:
            passed_labels.append(label_id)

    # Draw contours
    img = Image.fromarray(colored_img)
    draw = ImageDraw.Draw(img)

    # Draw failed clusters in red (draw first so passed are on top)
    for label_id in failed_labels:
        binary_mask = (label_mip == label_id).astype(np.uint8)
        contours = measure.find_contours(binary_mask, 0.5)
        for contour in contours:
            points = [(int(p[1]), int(p[0])) for p in contour]
            if len(points) > 2:
                draw.line(points + [points[0]], fill=(255, 0, 0), width=2)  # Red

    # Draw passed clusters in green/cyan
    passed_color = (0, 255, 255) if channel == 'green' else (0, 255, 0)  # Cyan for green channel, green for orange
    for label_id in passed_labels:
        binary_mask = (label_mip == label_id).astype(np.uint8)
        contours = measure.find_contours(binary_mask, 0.5)
        for contour in contours:
            points = [(int(p[1]), int(p[0])) for p in contour]
            if len(points) > 2:
                draw.line(points + [points[0]], fill=passed_color, width=2)

    overlay_rgb = np.array(img)

    # Draw spots
    if spots_df is not None and len(spots_df) > 0:
        overlay_rgb = draw_spots(overlay_rgb, spots_df, color=(255, 255, 255), radius=2)

    # Add scale bar
    overlay_rgb = draw_scale_bar(overlay_rgb, scale_um=50)

    imwrite(output_path, overlay_rgb)

    n_passed = len(passed_labels)
    n_failed = len(failed_labels)
    print(f"  Saved threshold filter view: {n_passed} passed (cyan/green), {n_failed} failed (red)")

    return overlay_rgb


def save_overview_with_colorbar(image_3d: np.ndarray, label_mask: np.ndarray,
                                 cluster_info: dict, spots_df: pd.DataFrame,
                                 channel: str, color_by: str,
                                 output_path: Path, slide: str = None):
    """
    Save overview image with cluster CONTOURS colored by intensity or volume.

    Uses contour visualization (like overview_spots_clusters.tif) but with
    color-coded contours based on intensity or volume values.

    Args:
        image_3d: 3D image (z, y, x)
        label_mask: 3D label mask
        cluster_info: dict with 'intensities', 'sizes', 'peak_intensity'
        spots_df: DataFrame with spot positions
        channel: 'green' or 'orange'
        color_by: 'intensity' (mRNA equiv.) or 'volume' (µm³)
        output_path: where to save (TIFF)
        slide: slide name for negative control threshold lookup (e.g., 'm3a1')
    """
    mip = create_mip(image_3d)
    mip_8bit = normalize_to_8bit(mip)
    colored_img = create_colored_image(mip_8bit, channel)
    label_mip = np.max(label_mask, axis=0)

    # Get values for coloring
    unique_labels = np.unique(label_mip)
    unique_labels = unique_labels[unique_labels > 0]

    peak_intensity = cluster_info.get('peak_intensity', np.nan)
    intensities = cluster_info['intensities']
    cvs = cluster_info.get('cvs', None)
    sizes = cluster_info['sizes']
    label_to_idx = cluster_info.get('label_to_idx', {})

    # Get negative control threshold for this slide/channel
    threshold = None
    if slide is not None:
        threshold = get_photon_threshold(slide, channel)
        if not np.isnan(threshold):
            print(f"    Using negative control threshold for {slide}/{channel}: {threshold:.0f} photons")
        else:
            print(f"    WARNING: No negative control threshold for {slide}/{channel}, showing all clusters")
            threshold = None

    # Diagnostic: count how many pass/fail threshold
    n_total = len(unique_labels)
    n_passed = 0
    n_failed = 0
    n_cv_failed = 0
    failed_intensities = []

    # Map labels to values (only those above threshold)
    label_values = {}
    for label_id in unique_labels:
        # Use label_to_idx mapping to get correct intensity index
        if label_id not in label_to_idx:
            continue
        idx = label_to_idx[label_id]
        if idx >= len(intensities):
            continue

        raw_intensity = intensities[idx]

        # Apply CV filtering (CV >= CV_THRESHOLD means good quality)
        if cvs is not None and idx < len(cvs) and cvs[idx] < CV_THRESHOLD:
            n_cv_failed += 1
            continue  # Skip clusters with low CV (poor quality)

        # Apply negative control threshold
        if threshold is not None and raw_intensity <= threshold:
            n_failed += 1
            failed_intensities.append(raw_intensity)
            continue
        n_passed += 1

        if color_by == 'intensity':
            if not np.isnan(peak_intensity) and peak_intensity > 0:
                label_values[label_id] = raw_intensity / peak_intensity
            else:
                label_values[label_id] = raw_intensity / 1000
        else:  # volume
            # sizes is now indexed by label_id directly (from bincount)
            if label_id < len(sizes):
                label_values[label_id] = sizes[label_id] * VOXEL_VOLUME_UM3
            else:
                label_values[label_id] = 0

    # Print diagnostic info
    if color_by == 'intensity':  # Only print once per channel
        if n_cv_failed > 0:
            print(f"    CV filter: {n_cv_failed} clusters excluded (CV < {CV_THRESHOLD})")
        if threshold is not None:
            print(f"    Threshold filter: {n_passed} passed, {n_failed} failed out of {n_total - n_cv_failed} clusters (after CV filter)")
            if failed_intensities:
                print(f"    Failed cluster intensities: min={min(failed_intensities):.0f}, max={max(failed_intensities):.0f}, median={np.median(failed_intensities):.0f} photons")
                print(f"    In mRNA equiv: min={min(failed_intensities)/peak_intensity:.2f}, max={max(failed_intensities)/peak_intensity:.2f}, median={np.median(failed_intensities)/peak_intensity:.2f}")

    if not label_values:
        # No valid clusters, save base image with scale bar
        img_with_scale = draw_scale_bar(colored_img, scale_um=50)
        imwrite(output_path, img_with_scale)
        return img_with_scale

    values = list(label_values.values())
    vmin = np.percentile(values, 5)
    vmax = np.percentile(values, 95)

    # Colormap
    if color_by == 'intensity':
        cmap = plt.colormaps['viridis']
    else:
        cmap = plt.colormaps['plasma']

    norm = Normalize(vmin=vmin, vmax=vmax)

    # Draw color-coded contours (like overview_spots_clusters but with colors)
    img = Image.fromarray(colored_img)
    draw = ImageDraw.Draw(img)

    for label_id, value in label_values.items():
        binary_mask = (label_mip == label_id).astype(np.uint8)
        contours = measure.find_contours(binary_mask, 0.5)

        # Get color from colormap
        color = cmap(norm(value))[:3]
        color_255 = tuple(int(c * 255) for c in color)

        for contour in contours:
            points = [(int(p[1]), int(p[0])) for p in contour]
            if len(points) > 2:
                draw.line(points + [points[0]], fill=color_255, width=2)

    overlay_rgb = np.array(img)

    # Draw spots
    if spots_df is not None and len(spots_df) > 0:
        overlay_rgb = draw_spots(overlay_rgb, spots_df, color=(255, 255, 255), radius=2)

    # Add scale bar
    overlay_rgb = draw_scale_bar(overlay_rgb, scale_um=50)

    imwrite(output_path, overlay_rgb)
    return overlay_rgb, vmin, vmax


def save_colorbar_svg(vmin: float, vmax: float, color_by: str, output_path: Path):
    """
    Save a standalone colorbar as SVG.

    Args:
        vmin, vmax: colorbar range
        color_by: 'intensity' or 'volume'
        output_path: where to save SVG
    """
    if color_by == 'intensity':
        cmap = plt.colormaps['viridis']
        label = 'Cluster intensity (mRNA equiv.)'
    else:
        cmap = plt.colormaps['plasma']
        label = 'Cluster volume (µm³)'

    norm = Normalize(vmin=vmin, vmax=vmax)

    # Create horizontal colorbar figure
    fig, ax = plt.subplots(figsize=(4, 0.5))

    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=ax, orientation='horizontal')

    # Set ticks
    if color_by == 'intensity':
        if vmax >= 100:
            cbar.set_ticks([vmin, (vmin + vmax) / 2, vmax])
            cbar.set_ticklabels([f'{vmin:.0f}', f'{(vmin+vmax)/2:.0f}', f'{vmax:.0f}'])
        else:
            cbar.set_ticks([vmin, (vmin + vmax) / 2, vmax])
            cbar.set_ticklabels([f'{vmin:.1f}', f'{(vmin+vmax)/2:.1f}', f'{vmax:.1f}'])
    else:
        cbar.set_ticks([vmin, (vmin + vmax) / 2, vmax])
        cbar.set_ticklabels([f'{vmin:.1f}', f'{(vmin+vmax)/2:.1f}', f'{vmax:.1f}'])

    cbar.set_label(label, fontsize=10)
    ax.tick_params(labelsize=8)

    plt.tight_layout()
    fig.savefig(output_path, format='svg', bbox_inches='tight', transparent=True)
    plt.close(fig)


def create_spot_vs_cluster_comparisons(image_3d: np.ndarray, label_mask: np.ndarray,
                                        cluster_info: dict, spots_df: pd.DataFrame,
                                        channel: str, output_dir: Path, fov_key: str,
                                        n_examples: int = 10, zoom_size: int = 30):
    """
    Create side-by-side comparisons of single spots and clusters from the same FOV.

    Each comparison shows:
    - Left: a single spot zoomed in
    - Right: a cluster zoomed in (from the same FOV, same dynamic range)

    All pairs within a FOV share the same dynamic range for fair comparison.

    Title includes:
    - Spot intensity (in mRNA equivalents, should be ~1.0)
    - Cluster volume (in µm³)
    - Cluster intensity (in mRNA equivalents)

    Aims to show examples from different cluster size ranges:
    - Small clusters (2-10 mRNA equiv)
    - Medium clusters (10-50 mRNA equiv)
    - Large clusters (50+ mRNA equiv)

    Args:
        image_3d: 3D image (z, y, x)
        label_mask: 3D label mask
        cluster_info: dict with 'intensities', 'sizes', 'peak_intensity', 'label_to_idx'
        spots_df: DataFrame with spot positions ('pos_x', 'pos_y', 'photons')
        channel: 'green' or 'orange'
        output_dir: directory to save comparison images
        fov_key: FOV identifier for naming
        n_examples: number of comparison images to create
        zoom_size: size of each zoom panel in pixels (default 30 = ~4.8µm for closer view)
    """
    comp_dir = output_dir / 'spot_vs_cluster_comparisons'
    comp_dir.mkdir(exist_ok=True)

    # Get MIP for visualization
    mip = np.max(image_3d, axis=0)
    label_mip = np.max(label_mask, axis=0)
    h, w = mip.shape

    # Get peak intensity for mRNA equivalent conversion
    peak_intensity = cluster_info.get('peak_intensity', np.nan)
    if np.isnan(peak_intensity) or peak_intensity <= 0:
        print(f"  WARNING: No valid peak intensity for mRNA conversion")
        return []

    # Get cluster properties
    intensities = cluster_info['intensities']
    sizes = cluster_info['sizes']
    label_to_idx = cluster_info.get('label_to_idx', {})

    # Build list of valid clusters with their properties
    clusters = []
    unique_labels = np.unique(label_mip)
    unique_labels = unique_labels[unique_labels > 0]

    for label_id in unique_labels:
        if label_id not in label_to_idx:
            continue
        idx = label_to_idx[label_id]
        if idx >= len(intensities):
            continue

        raw_intensity = intensities[idx]
        mrna_equiv = raw_intensity / peak_intensity

        # Skip clusters with < 2 mRNA equiv (likely noise)
        if mrna_equiv < 2.0:
            continue

        # Get cluster centroid from the MIP
        cluster_mask = label_mip == label_id
        ys, xs = np.where(cluster_mask)
        if len(xs) == 0:
            continue

        cx, cy = int(np.mean(xs)), int(np.mean(ys))

        # Check bounds (need margin for zoom)
        margin = zoom_size // 2 + 5
        if cx < margin or cx > w - margin or cy < margin or cy > h - margin:
            continue

        # Get volume
        if label_id < len(sizes):
            volume_um3 = sizes[label_id] * VOXEL_VOLUME_UM3
        else:
            volume_um3 = 0

        clusters.append({
            'label_id': label_id,
            'cx': cx,
            'cy': cy,
            'mrna_equiv': mrna_equiv,
            'volume_um3': volume_um3,
            'raw_intensity': raw_intensity,
        })

    if len(clusters) == 0:
        print(f"  No valid clusters found for comparison")
        return []

    # Build list of valid spots
    spots = []
    if spots_df is not None and len(spots_df) > 0 and 'photons' in spots_df.columns:
        for _, row in spots_df.iterrows():
            sx, sy = int(row['pos_x']), int(row['pos_y'])

            # Check bounds
            margin = zoom_size // 2 + 5
            if sx < margin or sx > w - margin or sy < margin or sy > h - margin:
                continue

            photons = row['photons']
            spot_mrna = photons / peak_intensity

            # Filter for spots that look like single mRNA (0.5-2.0 mRNA equiv)
            if spot_mrna < 0.5 or spot_mrna > 2.0:
                continue

            spots.append({
                'sx': sx,
                'sy': sy,
                'photons': photons,
                'mrna_equiv': spot_mrna,
            })

    if len(spots) == 0:
        print(f"  No valid single spots found for comparison")
        return []

    print(f"  Found {len(spots)} valid spots and {len(clusters)} valid clusters")

    # Sort clusters by mRNA equivalent for diverse size selection
    clusters_df = pd.DataFrame(clusters)
    clusters_df = clusters_df.sort_values('mrna_equiv')

    # Select clusters from different size ranges
    # Small (2-10), medium (10-50), large (50+)
    small = clusters_df[clusters_df['mrna_equiv'] < 10]
    medium = clusters_df[(clusters_df['mrna_equiv'] >= 10) & (clusters_df['mrna_equiv'] < 50)]
    large = clusters_df[clusters_df['mrna_equiv'] >= 50]

    # Allocate examples across size ranges
    n_small = min(len(small), n_examples // 3 + 1)
    n_medium = min(len(medium), n_examples // 3 + 1)
    n_large = min(len(large), n_examples // 3 + 1)

    # If we don't have enough in some categories, redistribute
    total_available = n_small + n_medium + n_large
    if total_available < n_examples:
        # Take more from categories that have extras
        remaining = n_examples - total_available
        if len(small) > n_small:
            extra = min(remaining, len(small) - n_small)
            n_small += extra
            remaining -= extra
        if remaining > 0 and len(medium) > n_medium:
            extra = min(remaining, len(medium) - n_medium)
            n_medium += extra
            remaining -= extra
        if remaining > 0 and len(large) > n_large:
            extra = min(remaining, len(large) - n_large)
            n_large += extra

    # Sample from each category
    selected_clusters = []
    if n_small > 0 and len(small) > 0:
        selected_clusters.extend(small.sample(n=min(n_small, len(small)), random_state=42).to_dict('records'))
    if n_medium > 0 and len(medium) > 0:
        selected_clusters.extend(medium.sample(n=min(n_medium, len(medium)), random_state=43).to_dict('records'))
    if n_large > 0 and len(large) > 0:
        selected_clusters.extend(large.sample(n=min(n_large, len(large)), random_state=44).to_dict('records'))

    # Limit to n_examples
    selected_clusters = selected_clusters[:n_examples]

    # Sample spots (random selection)
    spots_df_sample = pd.DataFrame(spots)
    if len(spots_df_sample) > n_examples:
        spots_df_sample = spots_df_sample.sample(n=n_examples, random_state=42)
    selected_spots = spots_df_sample.to_dict('records')

    # Create comparison images
    saved_paths = []

    # First pass: extract all zoom regions to compute FOV-wide dynamic range
    all_regions = []
    region_info = []  # Store (spot, cluster, spot_coords, cluster_coords) for each pair

    for i, cluster in enumerate(selected_clusters):
        if i >= len(selected_spots):
            break

        spot = selected_spots[i]

        # Extract zoom regions
        # Spot zoom
        sx, sy = spot['sx'], spot['sy']
        spot_x1 = max(0, sx - zoom_size // 2)
        spot_x2 = min(w, sx + zoom_size // 2)
        spot_y1 = max(0, sy - zoom_size // 2)
        spot_y2 = min(h, sy + zoom_size // 2)

        # Cluster zoom
        cx, cy = cluster['cx'], cluster['cy']
        clust_x1 = max(0, cx - zoom_size // 2)
        clust_x2 = min(w, cx + zoom_size // 2)
        clust_y1 = max(0, cy - zoom_size // 2)
        clust_y2 = min(h, cy + zoom_size // 2)

        # Extract MIP regions
        spot_mip = mip[spot_y1:spot_y2, spot_x1:spot_x2]
        clust_mip = mip[clust_y1:clust_y2, clust_x1:clust_x2]

        # Collect all pixel values for FOV-wide dynamic range
        all_regions.append(spot_mip.ravel())
        all_regions.append(clust_mip.ravel())

        # Store region info for second pass
        region_info.append({
            'spot': spot,
            'cluster': cluster,
            'spot_mip': spot_mip,
            'clust_mip': clust_mip,
            'spot_coords': (spot_x1, spot_x2, spot_y1, spot_y2, sx, sy),
            'clust_coords': (clust_x1, clust_x2, clust_y1, clust_y2, cx, cy),
        })

    # Compute FOV-wide dynamic range (same for ALL pairs in this FOV)
    all_vals = np.concatenate(all_regions)
    vmin = np.percentile(all_vals, 1)
    vmax = np.percentile(all_vals, 99.5)
    print(f"  FOV-wide dynamic range: [{vmin:.1f}, {vmax:.1f}]")

    # Second pass: create and save images using FOV-wide dynamic range
    for i, info in enumerate(region_info):
        spot = info['spot']
        cluster = info['cluster']
        spot_mip = info['spot_mip']
        clust_mip = info['clust_mip']
        spot_x1, spot_x2, spot_y1, spot_y2, sx, sy = info['spot_coords']
        clust_x1, clust_x2, clust_y1, clust_y2, cx, cy = info['clust_coords']

        # Normalize both to the same range
        spot_norm = np.clip((spot_mip.astype(float) - vmin) / (vmax - vmin + 1e-10), 0, 1)
        clust_norm = np.clip((clust_mip.astype(float) - vmin) / (vmax - vmin + 1e-10), 0, 1)

        # Color the images
        if channel == 'green':
            spot_rgb = np.zeros((*spot_norm.shape, 3))
            spot_rgb[:, :, 1] = spot_norm
            clust_rgb = np.zeros((*clust_norm.shape, 3))
            clust_rgb[:, :, 1] = clust_norm
        else:  # orange
            spot_rgb = np.zeros((*spot_norm.shape, 3))
            spot_rgb[:, :, 0] = spot_norm
            spot_rgb[:, :, 1] = spot_norm * 0.65
            clust_rgb = np.zeros((*clust_norm.shape, 3))
            clust_rgb[:, :, 0] = clust_norm
            clust_rgb[:, :, 1] = clust_norm * 0.65

        # File naming
        size_category = 'small' if cluster['mrna_equiv'] < 10 else ('medium' if cluster['mrna_equiv'] < 50 else 'large')
        base_name = f'comparison_{i+1:02d}_{size_category}_{cluster["mrna_equiv"]:.0f}mrna'

        # --- Extract cluster contour for saving as JSON (for SVG collage) ---
        local_label_mip = label_mip[clust_y1:clust_y2, clust_x1:clust_x2]
        cluster_contour_mask = (local_label_mip == cluster['label_id']).astype(np.uint8)
        contours = []
        if cluster_contour_mask.shape[0] >= 2 and cluster_contour_mask.shape[1] >= 2 and np.any(cluster_contour_mask):
            contours = measure.find_contours(cluster_contour_mask, 0.5)

        # --- Save RAW TIFFs (no annotations, for collage) ---
        # Side-by-side combined image
        gap_px = 4  # Small gap between spot and cluster
        combined_h = max(spot_rgb.shape[0], clust_rgb.shape[0])
        combined_w = spot_rgb.shape[1] + gap_px + clust_rgb.shape[1]
        combined_rgb = np.zeros((combined_h, combined_w, 3), dtype=np.float32)

        # Place spot on left
        combined_rgb[:spot_rgb.shape[0], :spot_rgb.shape[1], :] = spot_rgb
        # Place cluster on right (after gap)
        combined_rgb[:clust_rgb.shape[0], spot_rgb.shape[1] + gap_px:, :] = clust_rgb

        # Save as TIFF (8-bit RGB, no annotations)
        combined_rgb_8bit = (combined_rgb * 255).astype(np.uint8)
        tiff_path = comp_dir / f'{base_name}.tif'
        imwrite(str(tiff_path), combined_rgb_8bit)

        # Save contour and spot circle coordinates as JSON for SVG collage maker
        # Contour is in cluster panel coordinates, offset by spot width + gap
        cluster_offset_x = spot_rgb.shape[1] + gap_px
        # Spot circle is in spot panel coordinates (no offset)
        local_sx = sx - spot_x1
        local_sy = sy - spot_y1
        spot_circle_radius = 4  # pixels

        annotation_data = {
            'spot_width': int(spot_rgb.shape[1]),
            'cluster_width': int(clust_rgb.shape[1]),
            'gap_px': gap_px,
            'cluster_offset_x': cluster_offset_x,
            'image_height': int(combined_h),
            'image_width': int(combined_w),
            # Spot circle (in spot panel, left side)
            'spot_circle': {
                'cx': float(local_sx),
                'cy': float(local_sy),
                'radius': spot_circle_radius
            },
            # Cluster contours (in combined image coordinates, offset to right side)
            'contours': [[{'x': float(p[1]) + cluster_offset_x, 'y': float(p[0])} for p in c] for c in contours]
        }
        with open(comp_dir / f'{base_name}_contour.json', 'w') as f:
            json.dump(annotation_data, f)

        # --- Save SVG with matplotlib (vector elements for circle and contour) ---
        fig, axes = plt.subplots(1, 2, figsize=(6, 3.5))

        # Plot spot
        axes[0].imshow(spot_rgb)
        axes[0].set_title(f"Single spot\n{spot['mrna_equiv']:.2f} mRNA equiv.", fontsize=10)
        axes[0].axis('off')

        # Mark spot center with a circle (vector element, adjustable in SVG)
        local_sx = sx - spot_x1
        local_sy = sy - spot_y1
        spot_circle_radius = 4  # pixels
        circle = plt.Circle((local_sx, local_sy), spot_circle_radius,
                            fill=False, color='white', linewidth=1.5, alpha=0.9)
        axes[0].add_patch(circle)

        # Plot cluster
        axes[1].imshow(clust_rgb)
        axes[1].set_title(f"Cluster\n{cluster['mrna_equiv']:.1f} mRNA equiv., {cluster['volume_um3']:.2f} µm³", fontsize=10)
        axes[1].axis('off')

        # Draw cluster contour (vector element, adjustable in SVG)
        for contour in contours:
            axes[1].plot(contour[:, 1], contour[:, 0], 'w-', linewidth=1.5, alpha=0.9)

        # Overall title
        fig.suptitle(f'{channel.capitalize()} channel - FOV: {fov_key.split("--")[1] if "--" in fov_key else fov_key[:30]}',
                     fontsize=9, y=0.98)

        plt.tight_layout()

        # Save SVG (vector format, elements adjustable)
        out_path = comp_dir / f'{base_name}.svg'
        fig.savefig(out_path, format='svg', bbox_inches='tight', facecolor='black')
        plt.close(fig)
        saved_paths.append(out_path)

        print(f"    Saved {base_name}: spot={spot['mrna_equiv']:.2f} vs cluster={cluster['mrna_equiv']:.1f} mRNA, {cluster['volume_um3']:.2f}µm³")

    # Save summary info
    with open(comp_dir / 'comparison_summary.txt', 'w') as f:
        f.write(f"Spot vs Cluster Comparison Summary\n")
        f.write(f"{'='*50}\n\n")
        f.write(f"FOV: {fov_key}\n")
        f.write(f"Channel: {channel}\n")
        f.write(f"Peak intensity (single mRNA): {peak_intensity:.2f} photons\n\n")
        f.write(f"Total valid spots: {len(spots)}\n")
        f.write(f"Total valid clusters: {len(clusters)}\n")
        f.write(f"  - Small (<10 mRNA): {len(small)}\n")
        f.write(f"  - Medium (10-50 mRNA): {len(medium)}\n")
        f.write(f"  - Large (>50 mRNA): {len(large)}\n\n")
        f.write(f"Comparisons generated: {len(saved_paths)}\n\n")

        f.write(f"Individual comparisons:\n")
        f.write(f"{'-'*50}\n")
        for i, cluster in enumerate(selected_clusters[:len(saved_paths)]):
            spot = selected_spots[i]
            density = cluster['mrna_equiv'] / cluster['volume_um3'] if cluster['volume_um3'] > 0 else 0
            f.write(f"  {i+1}. Spot: {spot['mrna_equiv']:.2f} mRNA ({spot['photons']:.0f} photons)\n")
            f.write(f"     Cluster: {cluster['mrna_equiv']:.1f} mRNA, {cluster['volume_um3']:.2f} µm³, density: {density:.2f} mRNA/µm³\n\n")

    print(f"  Created {len(saved_paths)} spot vs cluster comparisons in {comp_dir}")
    return saved_paths


# EXCLUDED_SLIDES is imported from results_config


def find_regular_fovs(h5_path: str, n_fovs: int = 3, diverse_animals: bool = True, seed: int = 42):
    """
    Find regular FOVs (not extreme) with moderate cluster counts.
    Returns FOVs near the median of the distribution.

    Args:
        h5_path: Path to HDF5 file
        n_fovs: Number of FOVs to return
        diverse_animals: If True, ensure FOVs are from different animals/slides
        seed: Random seed for reproducibility
    """
    np.random.seed(seed)  # Set seed for reproducible selection
    rows = []

    # Debug counters
    n_total = 0
    n_excluded_slide = 0
    n_not_experimental = 0
    n_not_slidesno2 = 0
    n_no_clusters = 0

    with h5py.File(h5_path, 'r') as f:
        for fov_key in list(f.keys()):
            fov = f[fov_key]
            n_total += 1

            try:
                # Check if slide should be excluded
                slide = extract_slide_from_fov_key(fov_key)
                if slide is not None and slide.lower() in EXCLUDED_SLIDES:
                    n_excluded_slide += 1
                    continue

                # Filter for Q111 experimental only
                probe_set = fov['metadata_sample/Probe-Set'][()]
                if hasattr(probe_set, '__len__') and len(probe_set) > 0:
                    ps = probe_set[0]
                    if isinstance(ps, bytes):
                        ps = ps.decode()
                    if 'Experimental' not in ps:
                        n_not_experimental += 1
                        continue
                else:
                    n_not_experimental += 1
                    continue

                # Check if slidesno2 (local data)
                file_path = fov['general_metadata/file_path'][()]
                if isinstance(file_path, bytes):
                    file_path = file_path.decode()
                if 'slidesno2' not in file_path.lower() and 'newillumination' not in file_path.lower():
                    n_not_slidesno2 += 1
                    continue  # Only use slidesno2 which is available locally

                # Get cluster data
                green_intensities = fov['green/cluster_intensities'][:]
                green_sizes = fov['green/label_sizes'][:]
                orange_intensities = fov['orange/cluster_intensities'][:]
                orange_sizes = fov['orange/label_sizes'][:]

                # Extract slide/animal name
                slide = extract_slide_from_fov_key(fov_key)

                if len(green_intensities) < 20 or len(orange_intensities) < 20:
                    n_no_clusters += 1
                    continue

                if len(green_intensities) >= 20 and len(orange_intensities) >= 20:
                    rows.append({
                        'fov_key': fov_key,
                        'slide': slide,
                        'green_n': len(green_intensities),
                        'green_mean_size': np.mean(green_sizes) if len(green_sizes) > 0 else 0,
                        'orange_n': len(orange_intensities),
                        'orange_mean_size': np.mean(orange_sizes) if len(orange_sizes) > 0 else 0,
                        'total_clusters': len(green_intensities) + len(orange_intensities),
                    })
            except Exception as e:
                continue

    # Debug output
    print(f"  FOV filtering summary:")
    print(f"    Total FOVs checked: {n_total}")
    print(f"    Excluded slides ({EXCLUDED_SLIDES}): {n_excluded_slide}")
    print(f"    Not experimental: {n_not_experimental}")
    print(f"    Not slidesno2/newillumination: {n_not_slidesno2}")
    print(f"    Insufficient clusters (<20): {n_no_clusters}")
    print(f"    Passed all filters: {len(rows)}")

    df = pd.DataFrame(rows)
    if len(df) == 0:
        return []

    # Find FOVs near the median (regular, not extreme)
    median_clusters = df['total_clusters'].median()
    df['dist_from_median'] = np.abs(df['total_clusters'] - median_clusters)
    df_sorted = df.sort_values('dist_from_median')

    if diverse_animals and 'slide' in df_sorted.columns:
        # Select FOVs from different animals/slides
        selected = []
        used_slides = set()
        for _, row in df_sorted.iterrows():
            slide = row['slide']
            if slide is None or slide not in used_slides:
                selected.append(row['fov_key'])
                if slide is not None:
                    used_slides.add(slide)
                if len(selected) >= n_fovs * 2:  # Extra to handle missing NPZ
                    break
        print(f"Selected FOVs from {len(used_slides)} different animals/slides: {sorted(used_slides)}")
        return selected
    else:
        # Return FOVs closest to median
        return df_sorted.head(n_fovs * 2)['fov_key'].tolist()  # Extra to handle missing NPZ


def process_fov(fov_key: str, h5_path: str, output_dir: Path):
    """Process a single FOV and generate all visualizations."""

    # Get NPZ path
    npz_path = get_npz_path_from_h5(fov_key, h5_path)
    if npz_path is None:
        print(f"  Could not find NPZ for {fov_key}")
        return None

    print(f"\n{'='*60}")
    print(f"Processing: {fov_key}")
    print(f"NPZ: {npz_path}")
    print(f"{'='*60}")

    output_dir.mkdir(parents=True, exist_ok=True)

    # Load raw image
    image_4d, metadata = load_npz_image(npz_path)
    print(f"Image shape: {image_4d.shape}")

    cfg = get_local_cfg()
    color_config = get_color_config()
    detection_cfg = get_detection_cfg()
    fit_cfg = get_fit_cfg()

    results = {}

    for channel in ['green', 'orange']:
        print(f"\n--- Processing {channel} channel ---")

        ch_idx = CHANNEL_MAP[channel]
        image_3d = image_4d[ch_idx]

        # Process with full pipeline (pass fov_key for slide-specific peak intensity lookup)
        label_mask, spots_df, cluster_info = process_channel_with_pruning(
            npz_path, channel, cfg, color_config[channel], detection_cfg, fit_cfg,
            fov_key=fov_key
        )

        if label_mask is None:
            print(f"  Failed to process {channel}")
            continue

        label_mip = np.max(label_mask, axis=0)

        # Create output subdirectory
        ch_dir = output_dir / channel
        ch_dir.mkdir(exist_ok=True)

        # Save clean overview (raw image only, no labels)
        clean_overview_path = ch_dir / 'overview_clean.tif'
        save_clean_overview(image_3d, channel, clean_overview_path)
        print(f"  Saved clean overview: {clean_overview_path.name}")

        # Save overview (basic with contours)
        overview_path = ch_dir / 'overview_spots_clusters.tif'
        save_overview_image(image_3d, label_mask, spots_df, channel,
                           overview_path)
        print(f"  Saved overview: {overview_path.name}")

        # Extract slide for threshold lookup
        slide = extract_slide_from_fov_key(fov_key)

        # Save overview showing passed/failed threshold filter
        overview_filter_path = ch_dir / 'overview_threshold_filter.tif'
        save_overview_threshold_filter(
            image_3d, label_mask, cluster_info, spots_df, channel,
            overview_filter_path, slide=slide
        )

        # Save overview with intensity colormap
        overview_int_path = ch_dir / 'overview_intensity.tif'
        result = save_overview_with_colorbar(
            image_3d, label_mask, cluster_info, spots_df, channel,
            color_by='intensity', output_path=overview_int_path, slide=slide
        )
        if isinstance(result, tuple):
            _, vmin_int, vmax_int = result
            print(f"  Saved overview intensity: {overview_int_path.name}")
            # Save intensity colorbar SVG
            colorbar_int_path = ch_dir / 'colorbar_intensity.svg'
            save_colorbar_svg(vmin_int, vmax_int, 'intensity', colorbar_int_path)
            print(f"  Saved: {colorbar_int_path.name}")
        else:
            vmin_int, vmax_int = 0, 100

        # Save overview with volume colormap
        overview_vol_path = ch_dir / 'overview_volume.tif'
        result = save_overview_with_colorbar(
            image_3d, label_mask, cluster_info, spots_df, channel,
            color_by='volume', output_path=overview_vol_path, slide=slide
        )
        if isinstance(result, tuple):
            _, vmin_vol, vmax_vol = result
            print(f"  Saved overview volume: {overview_vol_path.name}")
            # Save volume colorbar SVG
            colorbar_vol_path = ch_dir / 'colorbar_volume.svg'
            save_colorbar_svg(vmin_vol, vmax_vol, 'volume', colorbar_vol_path)
            print(f"  Saved: {colorbar_vol_path.name}")
        else:
            vmin_vol, vmax_vol = 0, 30

        # Save label mask
        imwrite(ch_dir / 'label_mask_mip.tif', label_mip.astype(np.uint16))

        # Generate 5 zoomed images in 4 styles (clean, spots+clusters, intensity, volume)
        zoom_paths, zoom_centers = save_zoom_images(
            image_3d, label_mask, cluster_info, spots_df,
            channel, ch_dir, n_zooms=5, slide=slide,
            vmin_int=vmin_int, vmax_int=vmax_int,
            vmin_vol=vmin_vol, vmax_vol=vmax_vol
        )

        # Generate spot vs cluster comparison images
        print(f"\n  Generating spot vs cluster comparisons...")
        create_spot_vs_cluster_comparisons(
            image_3d, label_mask, cluster_info, spots_df,
            channel, ch_dir, fov_key, n_examples=10, zoom_size=30
        )

        # Save metadata
        peak_intensity = cluster_info.get('peak_intensity', np.nan)
        with open(ch_dir / 'metadata.txt', 'w') as f:
            f.write(f"FOV Key: {fov_key}\n")
            f.write(f"NPZ path: {npz_path}\n")
            f.write(f"Channel: {channel}\n")
            f.write(f"Image shape: {image_4d.shape}\n")
            f.write(f"\nClusters: {len(np.unique(label_mask)) - 1}\n")
            f.write(f"Spots: {len(spots_df)}\n")
            f.write(f"\nPeak intensity (KDE, sigma-filtered): {peak_intensity:.2f}\n")
            f.write(f"Cluster intensity range (photons): {cluster_info['intensities'].min():.1f} - {cluster_info['intensities'].max():.1f}\n")
            if not np.isnan(peak_intensity) and peak_intensity > 0:
                mrna_equiv = cluster_info['intensities'] / peak_intensity
                f.write(f"Cluster mRNA equiv. range: {mrna_equiv.min():.1f} - {mrna_equiv.max():.1f}\n")
                f.write(f"Cluster mRNA equiv. median: {np.median(mrna_equiv):.1f}\n")
            if len(cluster_info['sizes']) > 0:
                sizes_um3 = cluster_info['sizes'] * VOXEL_VOLUME_UM3
                f.write(f"Cluster size range: {sizes_um3.min():.2f} - {sizes_um3.max():.2f} µm³\n")
            f.write(f"\nColorbar ranges:\n")
            f.write(f"  Intensity: {vmin_int:.1f} - {vmax_int:.1f} mRNA equiv.\n")
            f.write(f"  Volume: {vmin_vol:.1f} - {vmax_vol:.1f} µm³\n")

        results[channel] = {
            'n_clusters': len(np.unique(label_mask)) - 1,
            'n_spots': len(spots_df),
        }

    return results


def main():
    """Generate Figure 2 panel images."""

    print("=" * 70)
    print("FIGURE 2 PANEL GENERATION")
    print("Using UNet-based cluster detection with label pruning")
    print("=" * 70)

    # Use H5 file from config
    h5_path = H5_FILE_PATH
    print(f"\nUsing H5 file: {h5_path}")

    # Find regular FOVs (not extreme)
    print("\nFinding regular FOVs (near median cluster count)...")
    candidate_fovs = find_regular_fovs(h5_path, n_fovs=25, diverse_animals=False)  # Get extra candidates

    if not candidate_fovs:
        print("No suitable FOVs found!")
        return

    print(f"Found {len(candidate_fovs)} candidate FOVs")

    # Process FOVs until we have enough
    results = {}
    n_processed = 0
    target_fovs = 20

    for fov_key in candidate_fovs:
        try:
            output_dir = OUTPUT_DIR / f'fov_{n_processed + 1}'
            result = process_fov(fov_key, h5_path, output_dir)

            if result:
                results[fov_key] = result
                n_processed += 1

                if n_processed >= target_fovs:
                    break

        except Exception as e:
            print(f"ERROR processing {fov_key}: {e}")
            traceback.print_exc()
            continue

    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)
    for fov_key, result in results.items():
        print(f"\n{fov_key[:60]}...")
        for channel, data in result.items():
            print(f"  {channel}: {data['n_clusters']} clusters, {data['n_spots']} spots")

    print(f"\nOutput saved to: {OUTPUT_DIR}")


if __name__ == '__main__':
    main()
