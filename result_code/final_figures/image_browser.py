#!/usr/bin/env python3
"""
Smart Image Browser for Figure Example Selection

This tool helps you browse and select example images from your RNA Scope data
for use in figure placeholders (A, B, D, I, etc. in figures 1-5).

Features:
- Filter by genotype (Q111 vs WT), probe set, channel, region, age
- Filter by FOV class: 'extreme' (> WT P95) vs 'normal' (≤ WT P95)
- Sort by spot count, cluster intensity, nuclei count, mRNA per cell
- View comprehensive metadata for each FOV
- Launch napari viewer for selected FOVs

Usage:
    # Interactive mode
    python image_browser.py

    # Command line with filters
    python image_browser.py --genotype Q111 --region striatum --probe experimental
    python image_browser.py --list-slides  # List all available slides
    python image_browser.py --slide "m3a1" --region "Striatum - upper left"

    # Filter by FOV class (extreme vs normal)
    python image_browser.py --fov-class extreme --channel mHTT1a
    python image_browser.py --fov-class normal --channel full-length

    # View specific FOV by path
    python image_browser.py --view "/path/to/fov.npz"
"""

import argparse
import os
import sys
import h5py
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import subprocess

# Add parent directory for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

# Import paths from results_config
from results_config import H5_FILE_PATH_EXPERIMENTAL, H5_FILE_PATH_BEAD

# ══════════════════════════════════════════════════════════════════════════════
# FOV-LEVEL DATA PATH (pre-computed from comprehensive analysis)
# ══════════════════════════════════════════════════════════════════════════════

# FOV-level data is generated by fig_expression_analysis_q111.py
FOV_LEVEL_DATA_PATH = Path(__file__).parent.parent / 'draft_figures' / 'output' / 'expression_analysis_q111' / 'fov_level_data.csv'

# ══════════════════════════════════════════════════════════════════════════════
# DATA PATH CONFIGURATION
# ══════════════════════════════════════════════════════════════════════════════

# H5 file paths from results_config
# - BEAD: Used for Panel D (sigma calibration reference)
# - EXPERIMENTAL: Used for Panel G (experimental data with PSF fitting)
H5_FILE_PATH_FOR_BEAD = H5_FILE_PATH_BEAD
H5_FILE_PATH_FOR_EXPERIMENTAL = H5_FILE_PATH_EXPERIMENTAL

# Default search paths (for backwards compatibility)
H5_FILE_SEARCH_PATHS = [
    H5_FILE_PATH_EXPERIMENTAL,
    H5_FILE_PATH_BEAD,
]

def find_h5_file(file_type: str = None):
    """
    Find an available H5 file.

    Args:
        file_type: 'bead', 'experimental', or None (search all)
    """
    if file_type == 'bead':
        if os.path.exists(H5_FILE_PATH_FOR_BEAD):
            return H5_FILE_PATH_FOR_BEAD
        return None
    elif file_type == 'experimental':
        if os.path.exists(H5_FILE_PATH_FOR_EXPERIMENTAL):
            return H5_FILE_PATH_FOR_EXPERIMENTAL
        return None
    else:
        # Search all paths
        for path in H5_FILE_SEARCH_PATHS:
            if os.path.exists(path):
                return path
        return None

RAW_DATA_DIRS = [
    "/media/grunwaldlab/SG Skyhawk AI 24TB/Q111 raw data/Q111_10slidesno1_june2025",
    "/media/grunwaldlab/SG Skyhawk AI 24TB/Q111 raw data/Q111_10slidesno2_june2025_new_illumination",
    "/media/grunwaldlab/SG Skyhawk AI 24TB/Q111 raw data/Q111_15slidesno1_june2025",
]

# Mapping from slide patterns to raw data directories
# Each dir has a nested structure: dir/annotated_folder/exported/Slide X - YZ/Region NNN/*.npz
SLIDE_TO_DIR = {
    'M3': RAW_DATA_DIRS[0],  # 10slidesno1
    'M1': RAW_DATA_DIRS[1],  # 10slidesno2
    'M2': RAW_DATA_DIRS[2],  # 15slidesno1
}


def recursively_load_dict(h5_group):
    """Recursively load an HDF5 group into a Python dictionary."""
    output = {}
    for key, item in h5_group.items():
        if isinstance(item, h5py.Dataset):
            output[key] = item[()]
        elif isinstance(item, h5py.Group):
            output[key] = recursively_load_dict(item)
    return output


def standardize_slide_name(slide_name: str) -> str:
    """Standardize slide name to format like 'm3a1'."""
    if pd.isna(slide_name):
        return None

    # Handle "Slide M3 - A1" -> "m3a1"
    name = str(slide_name).lower().strip()
    name = name.replace('slide', '').replace(' ', '').replace('-', '')
    return name


def parse_fov_key(key: str) -> Dict:
    """
    Parse FOV key into components.

    Handles two formats:
    - Old: 'Slide M3 - A1_Region_3_FOV_259'
    - New: 'q11110slidesno1june2025--m3a1--region003--313259--n0001'
    """
    parts = {}
    try:
        if '--' in key:
            # New format: q11110slidesno1june2025--m3a1--region003--313259--n0001
            segments = key.split('--')
            parts['dataset'] = segments[0]
            parts['slide_std'] = segments[1]  # Already standardized (e.g., 'm3a1')
            parts['slide_raw'] = f"Slide {segments[1][0:2].upper()} - {segments[1][2:].upper()}"
            parts['region_std'] = segments[2]
            parts['region_num'] = int(segments[2].replace('region', ''))
            parts['fov_num'] = int(segments[3])  # Original FOV number
            parts['n_index'] = segments[4] if len(segments) > 4 else None
        else:
            # Old format: Slide M3 - A1_Region_3_FOV_259
            slide_part = key.split('_Region_')[0]
            parts['slide_raw'] = slide_part
            parts['slide_std'] = standardize_slide_name(slide_part)

            region_fov = key.split('_Region_')[1]
            region_num = region_fov.split('_FOV_')[0]
            parts['region_num'] = int(region_num)

            fov_num = region_fov.split('_FOV_')[1]
            parts['fov_num'] = int(fov_num)

    except Exception as e:
        parts['error'] = str(e)

    return parts


def find_npz_path(slide_raw: str, region_num: int, fov_num: int, original_fov_num: int = None) -> Optional[str]:
    """
    Find the NPZ file path for a given slide/region/FOV.

    Args:
        slide_raw: Slide name like 'Slide M3 - A5'
        region_num: Region number (e.g., 9)
        fov_num: FOV number from H5 key (may be combined number like 359245)
        original_fov_num: Original FOV number from file path (e.g., 245) - use this if available
    """
    # Use original FOV number if provided, otherwise use fov_num
    search_fov = original_fov_num if original_fov_num is not None else fov_num

    # Determine which base directory to use
    slide_upper = slide_raw.upper()
    base_dir = None
    for pattern, dir_path in SLIDE_TO_DIR.items():
        if pattern in slide_upper:
            base_dir = dir_path
            break

    if base_dir is None:
        return None

    # Navigate to exported folder
    base_path = Path(base_dir)

    # Find the annotated folder (there may be variations in naming)
    annotated_folders = []
    for item in base_path.iterdir():
        if item.is_dir() and 'annotated' in item.name.lower():
            exported_path = item / 'exported'
            if exported_path.exists():
                annotated_folders.append(exported_path)

    # Also check for direct 'exported' folder
    direct_exported = base_path / 'exported'
    if direct_exported.exists():
        annotated_folders.append(direct_exported)

    for exported_path in annotated_folders:
        # Find the slide folder
        slide_folder = None
        for item in exported_path.iterdir():
            if item.is_dir() and slide_raw.lower().replace('_', ' - ') in item.name.lower():
                slide_folder = item
                break
            # Try exact match
            if item.is_dir() and slide_raw.lower() in item.name.lower().replace(' ', '').replace('-', ''):
                slide_folder = item
                break
            # More flexible match for "Slide M3 - A1" format
            slide_name_parts = slide_raw.lower().replace('slide', '').replace(' ', '').replace('-', '').replace('_', '')
            item_name_parts = item.name.lower().replace('slide', '').replace(' ', '').replace('-', '').replace('_', '')
            if slide_name_parts in item_name_parts:
                slide_folder = item
                break

        if slide_folder is None:
            continue

        # Find the region folder
        region_folder = None
        for item in slide_folder.iterdir():
            if item.is_dir() and f'Region {region_num:03d}' in item.name:
                region_folder = item
                break
            if item.is_dir() and f'Region {region_num}' in item.name:
                region_folder = item
                break

        if region_folder is None:
            continue

        # Find the NPZ file
        for npz_file in region_folder.glob('*.npz'):
            if f'FOV_{search_fov}' in npz_file.name:
                return str(npz_file)

    return None


def load_fov_metadata(h5_path: str = None) -> pd.DataFrame:
    """Load FOV-level metadata from H5 file."""

    if h5_path is None:
        h5_path = find_h5_file()

    if h5_path is None:
        print("ERROR: No H5 file found. Searched paths:")
        for p in H5_FILE_SEARCH_PATHS:
            print(f"  - {p}")
        print("\nPlease specify --h5-path explicitly.")
        sys.exit(1)

    print(f"Loading metadata from: {h5_path}")

    with h5py.File(h5_path, 'r') as f:
        data_dict = recursively_load_dict(f)

    # Build FOV-level dataframe
    rows = []

    for fov_key, fov_data in data_dict.items():
        if not isinstance(fov_data, dict):
            continue

        parsed = parse_fov_key(fov_key)
        if 'error' in parsed:
            continue

        row = {
            'fov_key': fov_key,
            'slide_raw': parsed['slide_raw'],
            'slide_std': parsed['slide_std'],
            'region_num': parsed['region_num'],
            'fov_num': parsed['fov_num'],
        }

        # Extract metadata_sample fields (handle both dict and h5 group formats)
        metadata_sample = fov_data.get('metadata_sample', {})
        if isinstance(metadata_sample, dict):
            # Helper to get value from array or scalar, decode bytes
            def get_val(d, *keys):
                for k in keys:
                    if k in d:
                        val = d[k]
                        if isinstance(val, np.ndarray):
                            val = val[0] if len(val) > 0 else None
                        if isinstance(val, bytes):
                            val = val.decode('utf-8')
                        return val
                return None

            row['age'] = get_val(metadata_sample, 'Age')
            row['mouse_model'] = get_val(metadata_sample, 'Mouse_Model', 'Mouse Model')
            row['mouse_id'] = get_val(metadata_sample, 'mouse_ID', 'mouse ID ', 'mouse ID')
            row['brain_region'] = get_val(metadata_sample, 'Brain_Region', 'Slice Region')
            row['probe_set'] = get_val(metadata_sample, 'Probe-Set')
            row['date'] = get_val(metadata_sample, 'Date')
            row['slide_name_std'] = get_val(metadata_sample, 'slide_name_std')

        # Extract original file path for NPZ location
        general_metadata = fov_data.get('general_metadata', {})
        if isinstance(general_metadata, dict):
            file_path = general_metadata.get('file_path', None)
            if file_path is not None:
                if isinstance(file_path, bytes):
                    file_path = file_path.decode('utf-8')
                elif isinstance(file_path, np.ndarray):
                    file_path = file_path.item() if file_path.size == 1 else str(file_path[0])
                    if isinstance(file_path, bytes):
                        file_path = file_path.decode('utf-8')
                row['original_file_path'] = file_path
                # Extract the original FOV number from the file path
                # e.g., "Slide M3 - A5_Region_9_FOV_245.npz" -> 245
                import re
                fov_match = re.search(r'FOV_(\d+)\.npz', str(file_path))
                if fov_match:
                    row['original_fov_num'] = int(fov_match.group(1))

        # Compute N_nuclei from blue channel label_sizes (same method as comprehensive analysis)
        # Import constants from results_config
        from results_config import VOXEL_SIZE, MEAN_NUCLEAR_VOLUME

        row['num_cells'] = 0
        row['N_nuclei'] = 0.0

        if 'blue' in fov_data:
            blue_data = fov_data['blue']
            if isinstance(blue_data, dict):
                # Get label_sizes to compute V_DAPI and N_nuclei
                label_sizes = blue_data.get('label_sizes', None)
                if label_sizes is not None:
                    try:
                        label_sizes = np.asarray(label_sizes)
                        V_DAPI = np.sum(label_sizes) * VOXEL_SIZE
                        N_nuclei = V_DAPI / MEAN_NUCLEAR_VOLUME
                        row['N_nuclei'] = N_nuclei
                        row['num_cells'] = N_nuclei  # Backward compatible
                    except:
                        pass

                # Also store the raw segment count
                num_cells_raw = blue_data.get('num_cells', 0)
                if isinstance(num_cells_raw, np.ndarray):
                    num_cells_raw = num_cells_raw.item() if num_cells_raw.size == 1 else 0
                row['num_segments'] = num_cells_raw

        # Count spots per channel
        for channel in ['green', 'orange', 'blue']:
            if channel in fov_data:
                ch_data = fov_data[channel]
                if isinstance(ch_data, dict):
                    spots = ch_data.get('spots', {})
                    if isinstance(spots, dict):
                        # Try different spot count methods
                        spot_count = 0

                        # Method 1: filter_indices (boolean mask)
                        filter_indices = spots.get('filter_indices')
                        if filter_indices is not None and len(filter_indices) > 0:
                            if filter_indices.dtype == bool:
                                spot_count = np.sum(filter_indices)
                            else:
                                spot_count = len(filter_indices)

                        # Method 2: photons array length
                        elif 'photons' in spots:
                            photons = spots.get('photons')
                            if photons is not None:
                                spot_count = len(photons)

                        # Method 3: final_filter (for older format)
                        elif 'final_filter' in spots:
                            final_filter = spots.get('final_filter', [])
                            if final_filter is not None and len(final_filter) > 0:
                                spot_count = np.sum(final_filter)

                        # Method 4: params_raw length (oldest format)
                        elif 'params_raw' in spots:
                            params_raw = spots.get('params_raw', [])
                            if params_raw is not None and len(params_raw) > 0:
                                spot_count = len(params_raw)

                        row[f'{channel}_spots'] = spot_count
                    else:
                        row[f'{channel}_spots'] = 0
                else:
                    row[f'{channel}_spots'] = 0

        # Calculate total spots
        row['total_spots'] = row.get('green_spots', 0) + row.get('orange_spots', 0)

        rows.append(row)

    df = pd.DataFrame(rows)
    print(f"Loaded {len(df)} FOVs")
    return df


def load_fov_level_data() -> Tuple[pd.DataFrame, Dict[Tuple[str, str], float]]:
    """
    Load pre-computed FOV-level data with mRNA quantification.

    Returns:
        df_fov: DataFrame with FOV-level data including mRNA per cell
        wt_p95_thresholds: Dict mapping (channel, region) -> WT 95th percentile
    """
    if not FOV_LEVEL_DATA_PATH.exists():
        print(f"WARNING: FOV-level data not found at {FOV_LEVEL_DATA_PATH}")
        print("Run the comprehensive analysis first to generate this file.")
        return None, {}

    print(f"Loading FOV-level data from: {FOV_LEVEL_DATA_PATH}")
    df_fov = pd.read_csv(FOV_LEVEL_DATA_PATH)

    # Standardize channel names
    df_fov['Channel'] = df_fov['Channel'].replace({'full length mHTT': 'full-length mHTT'})

    # Compute WT P95 thresholds for extreme/normal classification
    wt_p95_thresholds = {}

    for channel in df_fov['Channel'].unique():
        for region in ['Cortex', 'Striatum']:
            wt_data = df_fov[
                (df_fov['Mouse_Model'] == 'Wildtype') &
                (df_fov['Channel'] == channel) &
                (df_fov['Region'] == region)
            ]['Clustered_mRNA_per_Cell'].dropna()

            if len(wt_data) > 0:
                wt_p95 = np.percentile(wt_data, 95)
                wt_p95_thresholds[(channel, region)] = wt_p95

    # Add FOV class (extreme vs normal) for Q111 samples
    def classify_fov(row):
        if row['Mouse_Model'] != 'Q111':
            return 'N/A'

        threshold = wt_p95_thresholds.get((row['Channel'], row['Region']), np.nan)
        if np.isnan(threshold):
            return 'Unknown'

        clustered_mrna = row.get('Clustered_mRNA_per_Cell', np.nan)
        if np.isnan(clustered_mrna):
            return 'Unknown'

        return 'Extreme' if clustered_mrna > threshold else 'Normal'

    df_fov['FOV_Class'] = df_fov.apply(classify_fov, axis=1)

    # Print summary
    print(f"  Loaded {len(df_fov)} FOV records")
    print(f"  WT P95 thresholds:")
    for (ch, reg), val in sorted(wt_p95_thresholds.items()):
        print(f"    {ch} / {reg}: {val:.2f} mRNA/cell")

    # Count extreme/normal
    q111_data = df_fov[df_fov['Mouse_Model'] == 'Q111']
    extreme_count = (q111_data['FOV_Class'] == 'Extreme').sum()
    normal_count = (q111_data['FOV_Class'] == 'Normal').sum()
    print(f"  Q111 FOV classification: {extreme_count} Extreme, {normal_count} Normal")

    return df_fov, wt_p95_thresholds


def merge_h5_with_fov_data(df_h5: pd.DataFrame, df_fov: pd.DataFrame) -> pd.DataFrame:
    """
    Merge H5 metadata with FOV-level quantification data.

    The H5 data has one row per FOV (unique FOV identifiers).
    The FOV data has one row per FOV per channel, but lacks the unique FOV key.

    We merge using slide + subregion + N_Nuclei (which should be unique per FOV).
    """
    if df_fov is None or len(df_fov) == 0:
        return df_h5

    # Round N_Nuclei for matching (to handle floating point differences)
    df_h5['num_cells_rounded'] = df_h5['num_cells'].round(2)

    # For each channel, merge based on slide + subregion + num_cells
    for channel, ch_color in [('mHTT1a', 'green'), ('full-length mHTT', 'orange')]:
        # Get channel-specific data
        channel_match = channel if channel != 'full-length mHTT' else 'full length mHTT'
        df_ch = df_fov[df_fov['Channel'].isin([channel, channel_match])].copy()

        if len(df_ch) == 0:
            continue

        # Round N_Nuclei for matching
        df_ch['N_Nuclei_rounded'] = df_ch['N_Nuclei'].round(2)

        # Create merge keys
        df_ch['slide_lower'] = df_ch['Slide'].str.lower()
        df_ch['subregion_lower'] = df_ch['Subregion'].str.lower()

        # Select columns to merge
        merge_cols = ['slide_lower', 'subregion_lower', 'N_Nuclei_rounded',
                      'Clustered_mRNA_per_Cell', 'Total_mRNA_per_Cell',
                      'Clusters_per_Cell', 'FOV_Class', 'N_Clusters', 'N_Spots']

        # Ensure no duplicate merge keys (take first if duplicates exist)
        df_ch_merge = df_ch[merge_cols].drop_duplicates(
            subset=['slide_lower', 'subregion_lower', 'N_Nuclei_rounded'],
            keep='first'
        )

        # Rename columns for this channel
        df_ch_merge = df_ch_merge.rename(columns={
            'Clustered_mRNA_per_Cell': f'{ch_color}_clustered_mrna_per_cell',
            'Total_mRNA_per_Cell': f'{ch_color}_total_mrna_per_cell',
            'Clusters_per_Cell': f'{ch_color}_clusters_per_cell',
            'FOV_Class': f'{ch_color}_fov_class',
            'N_Clusters': f'{ch_color}_n_clusters',
            'N_Spots': f'{ch_color}_n_spots_thresholded',
        })

        # Create merge keys in H5 data
        df_h5['slide_lower'] = df_h5['slide_std'].str.lower()
        df_h5['subregion_lower'] = df_h5['brain_region'].str.lower()

        # Merge
        df_h5 = df_h5.merge(
            df_ch_merge,
            left_on=['slide_lower', 'subregion_lower', 'num_cells_rounded'],
            right_on=['slide_lower', 'subregion_lower', 'N_Nuclei_rounded'],
            how='left'
        )

        # Drop temporary columns from FOV data
        df_h5 = df_h5.drop(columns=['N_Nuclei_rounded'], errors='ignore')

    # Drop temporary columns
    df_h5 = df_h5.drop(columns=['num_cells_rounded', 'slide_lower', 'subregion_lower'], errors='ignore')

    # Count successful merges
    merged_green = df_h5['green_fov_class'].notna().sum() if 'green_fov_class' in df_h5.columns else 0
    merged_orange = df_h5['orange_fov_class'].notna().sum() if 'orange_fov_class' in df_h5.columns else 0
    print(f"  Merged: {merged_green} FOVs with mHTT1a data, {merged_orange} FOVs with full-length data")

    return df_h5


def classify_region(brain_region: str) -> str:
    """Classify brain region as cortex, striatum, or other."""
    if pd.isna(brain_region):
        return 'unknown'
    region = str(brain_region).lower()
    if 'cortex' in region:
        return 'cortex'
    elif 'striatum' in region:
        return 'striatum'
    else:
        return 'other'


def classify_probe_set(probe_set: str) -> str:
    """Classify probe set as negative, positive, or experimental."""
    if pd.isna(probe_set):
        return 'unknown'
    ps = str(probe_set).lower()
    if 'negative' in ps:
        return 'negative_control'
    elif 'positive' in ps:
        return 'positive_control'
    elif 'experimental' in ps:
        return 'experimental'
    else:
        return 'other'


def filter_fovs(df: pd.DataFrame,
                genotype: str = None,
                probe_type: str = None,
                region_type: str = None,
                min_spots: int = None,
                max_spots: int = None,
                min_nuclei: int = None,
                slide: str = None,
                age: int = None,
                fov_class: str = None,
                channel: str = None) -> pd.DataFrame:
    """
    Filter FOVs based on criteria.

    Parameters:
        df: DataFrame with FOV metadata
        genotype: 'Q111' or 'Wildtype'
        probe_type: 'experimental', 'positive_control', 'negative_control'
        region_type: 'cortex', 'striatum'
        min_spots, max_spots: Spot count range
        min_nuclei: Minimum nuclei count
        slide: Slide name (e.g., 'm3a1')
        age: Age in months
        fov_class: 'extreme' or 'normal' (Q111 only, relative to WT P95)
        channel: 'mHTT1a' or 'full-length' - specifies which channel for fov_class filter
    """

    df_filtered = df.copy()

    if genotype:
        df_filtered = df_filtered[
            df_filtered['mouse_model'].str.lower().str.contains(genotype.lower(), na=False)
        ]

    if probe_type:
        df_filtered['probe_type'] = df_filtered['probe_set'].apply(classify_probe_set)
        df_filtered = df_filtered[df_filtered['probe_type'] == probe_type.lower()]

    if region_type:
        df_filtered['region_type'] = df_filtered['brain_region'].apply(classify_region)
        df_filtered = df_filtered[df_filtered['region_type'] == region_type.lower()]

    if min_spots is not None:
        df_filtered = df_filtered[df_filtered['total_spots'] >= min_spots]

    if max_spots is not None:
        df_filtered = df_filtered[df_filtered['total_spots'] <= max_spots]

    if min_nuclei is not None:
        df_filtered = df_filtered[df_filtered['num_cells'] >= min_nuclei]

    if slide:
        df_filtered = df_filtered[
            df_filtered['slide_std'].str.contains(slide.lower(), na=False)
        ]

    if age is not None:
        df_filtered = df_filtered[df_filtered['age'] == age]

    # Filter by FOV class (extreme vs normal)
    if fov_class:
        fov_class_lower = fov_class.lower()
        # Determine which channel column to use
        if channel:
            ch_lower = channel.lower()
            if 'full' in ch_lower:
                class_col = 'orange_fov_class'
            else:  # mhtt1a or green
                class_col = 'green_fov_class'
        else:
            # Default: use green (mHTT1a) channel
            class_col = 'green_fov_class'

        if class_col in df_filtered.columns:
            df_filtered = df_filtered[
                df_filtered[class_col].str.lower() == fov_class_lower
            ]
        else:
            print(f"WARNING: FOV class column '{class_col}' not found. "
                  "Make sure FOV-level data was loaded and merged.")

    return df_filtered


def print_fov_summary(df: pd.DataFrame, n_show: int = 20, sort_by: str = 'total_spots'):
    """Print a summary of FOVs with comprehensive metadata."""

    if len(df) == 0:
        print("No FOVs match the criteria.")
        return

    print(f"\n{'='*100}")
    print(f"Found {len(df)} FOVs matching criteria")
    print(f"{'='*100}")

    # Summary stats
    print(f"\nGenotypes: {df['mouse_model'].value_counts().to_dict()}")

    df['probe_type'] = df['probe_set'].apply(classify_probe_set)
    print(f"Probe types: {df['probe_type'].value_counts().to_dict()}")

    df['region_type'] = df['brain_region'].apply(classify_region)
    print(f"Region types: {df['region_type'].value_counts().to_dict()}")

    print(f"Slides: {sorted(df['slide_std'].dropna().unique())}")

    print(f"\nSpot counts: min={df['total_spots'].min():.0f}, "
          f"median={df['total_spots'].median():.0f}, "
          f"max={df['total_spots'].max():.0f}")

    print(f"Nuclei counts: min={df['num_cells'].min():.0f}, "
          f"median={df['num_cells'].median():.0f}, "
          f"max={df['num_cells'].max():.0f}")

    # FOV class summary if available
    if 'green_fov_class' in df.columns:
        green_class_counts = df['green_fov_class'].value_counts().to_dict()
        print(f"mHTT1a FOV class: {green_class_counts}")
    if 'orange_fov_class' in df.columns:
        orange_class_counts = df['orange_fov_class'].value_counts().to_dict()
        print(f"full-length FOV class: {orange_class_counts}")

    # Determine sort column
    sort_col = sort_by
    ascending = False
    if sort_by in ['total_spots', 'spots']:
        sort_col = 'total_spots'
    elif sort_by in ['nuclei', 'num_cells', 'cells']:
        sort_col = 'num_cells'
    elif sort_by == 'age':
        sort_col = 'age'
    elif sort_by in ['green_mrna', 'mhtt1a_mrna']:
        sort_col = 'green_clustered_mrna_per_cell'
    elif sort_by in ['orange_mrna', 'full_mrna']:
        sort_col = 'orange_clustered_mrna_per_cell'

    # Show top FOVs
    print(f"\n{'─'*100}")
    print(f"Top {min(n_show, len(df))} FOVs (sorted by {sort_by}):")
    print(f"{'─'*100}")

    if sort_col in df.columns:
        df_sorted = df.sort_values(sort_col, ascending=ascending, na_position='last').head(n_show)
    else:
        df_sorted = df.head(n_show)

    for idx, (_, row) in enumerate(df_sorted.iterrows()):
        original_fov = row.get('original_fov_num', None)
        npz_path = find_npz_path(row['slide_raw'], row['region_num'], row['fov_num'], original_fov)
        path_status = "✓" if npz_path else "✗"

        print(f"\n[{idx+1}] {row['fov_key']}")
        print(f"    ┌─ SAMPLE METADATA ─────────────────────────────────────────────────────")
        print(f"    │ Slide: {row['slide_std']} | Mouse ID: {row.get('mouse_id', 'N/A')}")
        print(f"    │ Genotype: {row.get('mouse_model', 'N/A')} | Age: {row.get('age', 'N/A')} months")
        print(f"    │ Region: {row.get('brain_region', 'N/A')}")
        print(f"    │ Probe Set: {row.get('probe_set', 'N/A')}")
        print(f"    │ Date: {row.get('date', 'N/A')}")
        print(f"    │")
        print(f"    ├─ RAW SPOT COUNTS ─────────────────────────────────────────────────────")
        print(f"    │ Green (mHTT1a): {row.get('green_spots', 0):.0f} spots")
        print(f"    │ Orange (full-length): {row.get('orange_spots', 0):.0f} spots")
        print(f"    │ Total: {row['total_spots']:.0f} spots | Nuclei: {row.get('num_cells', 0):.0f}")
        print(f"    │")

        # Show mRNA quantification if available
        if 'green_clustered_mrna_per_cell' in row and pd.notna(row.get('green_clustered_mrna_per_cell')):
            print(f"    ├─ mRNA QUANTIFICATION ─────────────────────────────────────────────────")
            green_mrna = row.get('green_clustered_mrna_per_cell', 0)
            orange_mrna = row.get('orange_clustered_mrna_per_cell', 0)
            green_class = row.get('green_fov_class', 'N/A')
            orange_class = row.get('orange_fov_class', 'N/A')
            green_clusters = row.get('green_clusters_per_cell', 0)
            orange_clusters = row.get('orange_clusters_per_cell', 0)

            print(f"    │ mHTT1a:      {green_mrna:.2f} mRNA/cell | {green_clusters:.2f} clusters/cell | Class: {green_class}")
            print(f"    │ full-length: {orange_mrna:.2f} mRNA/cell | {orange_clusters:.2f} clusters/cell | Class: {orange_class}")
            print(f"    │")

        print(f"    ├─ FILE PATH ───────────────────────────────────────────────────────────")
        print(f"    │ NPZ available: {path_status}")
        if npz_path:
            print(f"    │ Path: {npz_path}")
        print(f"    └───────────────────────────────────────────────────────────────────────")


def print_fov_detail(row: pd.Series):
    """Print comprehensive details for a single FOV - suitable for figure captions."""

    print(f"\n{'='*100}")
    print(f"FOV DETAILED METADATA FOR FIGURE")
    print(f"{'='*100}")

    print(f"\n┌─ IDENTIFICATION ────────────────────────────────────────────────────────────")
    print(f"│ FOV Key: {row['fov_key']}")
    print(f"│ Slide: {row['slide_std']} (raw: {row.get('slide_raw', 'N/A')})")
    print(f"│ Region Number: {row.get('region_num', 'N/A')} | FOV Number: {row.get('fov_num', 'N/A')}")
    print(f"│")
    print(f"├─ SAMPLE INFORMATION ─────────────────────────────────────────────────────────")
    print(f"│ Mouse Model: {row.get('mouse_model', 'N/A')}")
    print(f"│ Mouse ID: {row.get('mouse_id', 'N/A')}")
    print(f"│ Age: {row.get('age', 'N/A')} months")
    print(f"│ Brain Region: {row.get('brain_region', 'N/A')}")
    print(f"│ Probe Set: {row.get('probe_set', 'N/A')}")
    print(f"│ Date Acquired: {row.get('date', 'N/A')}")
    print(f"│")
    print(f"├─ QUANTIFICATION ─────────────────────────────────────────────────────────────")
    print(f"│ Nuclei count: {row.get('num_cells', 0):.0f}")
    print(f"│")
    print(f"│ GREEN CHANNEL (mHTT1a):")
    print(f"│   Raw spots: {row.get('green_spots', 0):.0f}")
    if 'green_clustered_mrna_per_cell' in row and pd.notna(row.get('green_clustered_mrna_per_cell')):
        print(f"│   Clustered mRNA/cell: {row.get('green_clustered_mrna_per_cell', 0):.2f}")
        print(f"│   Clusters/cell: {row.get('green_clusters_per_cell', 0):.3f}")
        print(f"│   FOV Classification: {row.get('green_fov_class', 'N/A')}")
    print(f"│")
    print(f"│ ORANGE CHANNEL (full-length mHTT):")
    print(f"│   Raw spots: {row.get('orange_spots', 0):.0f}")
    if 'orange_clustered_mrna_per_cell' in row and pd.notna(row.get('orange_clustered_mrna_per_cell')):
        print(f"│   Clustered mRNA/cell: {row.get('orange_clustered_mrna_per_cell', 0):.2f}")
        print(f"│   Clusters/cell: {row.get('orange_clusters_per_cell', 0):.3f}")
        print(f"│   FOV Classification: {row.get('orange_fov_class', 'N/A')}")
    print(f"│")

    original_fov = row.get('original_fov_num', None)
    npz_path = find_npz_path(row['slide_raw'], row['region_num'], row['fov_num'], original_fov)
    print(f"├─ FILE LOCATION ──────────────────────────────────────────────────────────────")
    if npz_path:
        print(f"│ NPZ File: {npz_path}")
        print(f"│ Filename: {Path(npz_path).name}")
    else:
        print(f"│ NPZ File: NOT FOUND")
        print(f"│ Expected: Slide {row.get('slide_raw', 'N/A')} / Region {row.get('region_num', 'N/A')} / FOV {row.get('fov_num', 'N/A')}")
    print(f"└──────────────────────────────────────────────────────────────────────────────")

    # Generate citation-ready text
    print(f"\n┌─ FIGURE CAPTION TEXT ────────────────────────────────────────────────────────")
    region_type = classify_region(row.get('brain_region', ''))
    genotype = row.get('mouse_model', 'Unknown')
    age = row.get('age', 'N/A')

    caption = f"Representative FOV from {genotype} mouse ({age} months), {region_type}"
    if 'green_fov_class' in row and pd.notna(row.get('green_fov_class')):
        green_class = row.get('green_fov_class', '')
        if green_class in ['Extreme', 'Normal']:
            caption += f", classified as '{green_class}' for mHTT1a expression"

    print(f"│ {caption}")
    print(f"│")
    print(f"│ Technical: Slide {row.get('slide_std', 'N/A')}, {row.get('brain_region', 'N/A')}")
    print(f"└──────────────────────────────────────────────────────────────────────────────")


def view_fov(npz_path: str, max_project: bool = True):
    """Launch napari viewer for a FOV."""

    view_script = Path(__file__).parent.parent.parent / 'view_npz_stack.py'

    cmd = ['python', str(view_script), npz_path]
    if max_project:
        cmd.append('--max-project')

    print(f"\nLaunching viewer: {' '.join(cmd)}")
    subprocess.run(cmd)


def interactive_browser(df: pd.DataFrame):
    """Interactive browser for selecting FOVs."""

    print("\n" + "="*100)
    print("INTERACTIVE IMAGE BROWSER")
    print("="*100)
    print("\nCommands:")
    print("  filter <field> <value>  - Filter by field:")
    print("                            genotype (Q111, Wildtype)")
    print("                            probe (experimental, positive_control, negative_control)")
    print("                            region (cortex, striatum)")
    print("                            slide (e.g., m3a1)")
    print("                            age (e.g., 2, 6, 12)")
    print("                            class <extreme|normal> [channel]  - Filter by FOV class")
    print("  sort <field>            - Sort by: spots, nuclei, age, green_mrna, orange_mrna")
    print("  show [n]                - Show top n results (default 20)")
    print("  detail <number>         - Show detailed metadata for FOV (for figure captions)")
    print("  view <number>           - View FOV in napari")
    print("  path <number>           - Show file path only")
    print("  reset                   - Reset filters")
    print("  quit                    - Exit")

    df_current = df.copy()
    last_shown = None
    current_sort = 'total_spots'

    while True:
        try:
            cmd = input("\n> ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if not cmd:
            continue

        parts = cmd.split()
        action = parts[0].lower()

        if action == 'quit' or action == 'q':
            break

        elif action == 'reset':
            df_current = df.copy()
            print("Filters reset.")

        elif action == 'filter' and len(parts) >= 3:
            field = parts[1].lower()
            value = ' '.join(parts[2:])

            if field == 'genotype':
                df_current = filter_fovs(df_current, genotype=value)
            elif field == 'probe':
                df_current = filter_fovs(df_current, probe_type=value)
            elif field == 'region':
                df_current = filter_fovs(df_current, region_type=value)
            elif field == 'slide':
                df_current = filter_fovs(df_current, slide=value)
            elif field == 'age':
                df_current = filter_fovs(df_current, age=int(value))
            elif field == 'class':
                # Parse: class <extreme|normal> [channel]
                class_parts = value.split()
                fov_class = class_parts[0]
                channel = class_parts[1] if len(class_parts) > 1 else None
                df_current = filter_fovs(df_current, fov_class=fov_class, channel=channel)
            else:
                print(f"Unknown filter field: {field}")
                print("Available: genotype, probe, region, slide, age, class")
                continue

            print(f"Filtered to {len(df_current)} FOVs")

        elif action == 'sort' and len(parts) >= 2:
            field = parts[1].lower()
            current_sort = field
            if field == 'spots':
                df_current = df_current.sort_values('total_spots', ascending=False)
            elif field == 'nuclei':
                df_current = df_current.sort_values('num_cells', ascending=False)
            elif field == 'age':
                df_current = df_current.sort_values('age', ascending=False)
            elif field in ['green_mrna', 'mhtt1a']:
                if 'green_clustered_mrna_per_cell' in df_current.columns:
                    df_current = df_current.sort_values('green_clustered_mrna_per_cell', ascending=False)
                else:
                    print("mRNA data not available. Load FOV-level data first.")
                    continue
            elif field in ['orange_mrna', 'full_mrna', 'full']:
                if 'orange_clustered_mrna_per_cell' in df_current.columns:
                    df_current = df_current.sort_values('orange_clustered_mrna_per_cell', ascending=False)
                else:
                    print("mRNA data not available. Load FOV-level data first.")
                    continue
            else:
                print(f"Unknown sort field: {field}")
                print("Available: spots, nuclei, age, green_mrna, orange_mrna")
                continue
            print(f"Sorted by {field}")

        elif action == 'show':
            n = int(parts[1]) if len(parts) > 1 else 20
            print_fov_summary(df_current, n_show=n, sort_by=current_sort)
            last_shown = df_current.head(n)

        elif action == 'detail' and len(parts) >= 2:
            # Show detailed metadata for a specific FOV
            try:
                idx = int(parts[1]) - 1  # 1-indexed for user
                if last_shown is None:
                    print("Run 'show' first to see available FOVs")
                    continue

                if idx < 0 or idx >= len(last_shown):
                    print(f"Invalid index. Use 1-{len(last_shown)}")
                    continue

                row = last_shown.iloc[idx]
                print_fov_detail(row)

            except ValueError:
                print("Invalid number")

        elif action == 'view' and len(parts) >= 2:
            try:
                idx = int(parts[1]) - 1  # 1-indexed for user
                if last_shown is None:
                    print("Run 'show' first to see available FOVs")
                    continue

                if idx < 0 or idx >= len(last_shown):
                    print(f"Invalid index. Use 1-{len(last_shown)}")
                    continue

                row = last_shown.iloc[idx]
                original_fov = row.get('original_fov_num', None)
                npz_path = find_npz_path(row['slide_raw'], row['region_num'], row['fov_num'], original_fov)

                if npz_path is None:
                    print(f"Could not find NPZ file for this FOV")
                    print(f"  Slide: {row['slide_raw']}")
                    print(f"  Region: {row['region_num']}")
                    print(f"  FOV: {row['fov_num']} (original: {original_fov})")
                else:
                    print(f"NPZ path: {npz_path}")
                    view = input("View in napari? (y/n): ").strip().lower()
                    if view == 'y':
                        view_fov(npz_path)

            except ValueError:
                print("Invalid number")

        elif action == 'path' and len(parts) >= 2:
            # Just show path without viewing
            try:
                idx = int(parts[1]) - 1
                if last_shown is None:
                    print("Run 'show' first")
                    continue

                if idx < 0 or idx >= len(last_shown):
                    print(f"Invalid index. Use 1-{len(last_shown)}")
                    continue

                row = last_shown.iloc[idx]
                original_fov = row.get('original_fov_num', None)
                npz_path = find_npz_path(row['slide_raw'], row['region_num'], row['fov_num'], original_fov)

                if npz_path:
                    print(f"\nNPZ path:\n{npz_path}")
                else:
                    print("Could not find NPZ file")

            except ValueError:
                print("Invalid number")

        else:
            print(f"Unknown command: {cmd}")
            print("Type 'quit' to exit, 'show' to see FOVs, or 'help' for commands")


def get_example_fovs_for_figures(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """Get recommended FOVs for each figure panel type."""

    recommendations = {}

    # For Figure 1 panels A, B, D, I - need representative experimental images
    # A: Overview/schematic (will be drawn separately)
    # B: Good negative control example
    # D: Good bead/calibration example
    # I: Good experimental tissue example

    print("\n" + "="*100)
    print("RECOMMENDED FOVs FOR FIGURE PANELS")
    print("="*100)

    # Negative control examples (for showing low background)
    df_neg = filter_fovs(df, probe_type='negative_control', min_nuclei=40)
    if len(df_neg) > 0:
        df_neg = df_neg.sort_values('total_spots', ascending=True)  # Want LOW spots
        recommendations['negative_control'] = df_neg.head(10)
        print(f"\nNegative control examples: {len(df_neg)} FOVs available")
        print(f"  Best example: {df_neg.iloc[0]['fov_key']} ({df_neg.iloc[0]['total_spots']:.0f} spots)")

    # Positive control examples (for showing probe working)
    df_pos = filter_fovs(df, probe_type='positive_control', min_nuclei=40)
    if len(df_pos) > 0:
        df_pos = df_pos.sort_values('total_spots', ascending=False)
        recommendations['positive_control'] = df_pos.head(10)
        print(f"\nPositive control examples: {len(df_pos)} FOVs available")
        print(f"  Best example: {df_pos.iloc[0]['fov_key']} ({df_pos.iloc[0]['total_spots']:.0f} spots)")

    # Experimental Q111 - high expression examples
    df_q111_high = filter_fovs(df, genotype='Q111', probe_type='experimental', min_nuclei=40)
    if len(df_q111_high) > 0:
        df_q111_high = df_q111_high.sort_values('total_spots', ascending=False)
        recommendations['q111_high'] = df_q111_high.head(10)
        print(f"\nQ111 high expression: {len(df_q111_high)} FOVs available")
        print(f"  Best example: {df_q111_high.iloc[0]['fov_key']} ({df_q111_high.iloc[0]['total_spots']:.0f} spots)")

    # Experimental WT - should have low/no mHTT signal
    df_wt = filter_fovs(df, genotype='Wildtype', probe_type='experimental', min_nuclei=40)
    if len(df_wt) > 0:
        df_wt = df_wt.sort_values('total_spots', ascending=True)
        recommendations['wt'] = df_wt.head(10)
        print(f"\nWT examples (should be low): {len(df_wt)} FOVs available")
        print(f"  Best example: {df_wt.iloc[0]['fov_key']} ({df_wt.iloc[0]['total_spots']:.0f} spots)")

    # Striatum examples (main region of interest)
    df_striatum = filter_fovs(df, genotype='Q111', probe_type='experimental',
                               region_type='striatum', min_nuclei=40)
    if len(df_striatum) > 0:
        df_striatum = df_striatum.sort_values('total_spots', ascending=False)
        recommendations['striatum'] = df_striatum.head(10)
        print(f"\nQ111 Striatum: {len(df_striatum)} FOVs available")
        print(f"  Best example: {df_striatum.iloc[0]['fov_key']} ({df_striatum.iloc[0]['total_spots']:.0f} spots)")

    # Cortex examples
    df_cortex = filter_fovs(df, genotype='Q111', probe_type='experimental',
                            region_type='cortex', min_nuclei=40)
    if len(df_cortex) > 0:
        df_cortex = df_cortex.sort_values('total_spots', ascending=False)
        recommendations['cortex'] = df_cortex.head(10)
        print(f"\nQ111 Cortex: {len(df_cortex)} FOVs available")
        print(f"  Best example: {df_cortex.iloc[0]['fov_key']} ({df_cortex.iloc[0]['total_spots']:.0f} spots)")

    # ══════════════════════════════════════════════════════════════════════════════
    # FIGURE 5: Extreme vs Normal FOVs
    # ══════════════════════════════════════════════════════════════════════════════
    print(f"\n{'─'*100}")
    print("FOR FIGURE 5 (Extreme vs Normal FOVs):")
    print(f"{'─'*100}")

    # Check if FOV class data is available
    has_fov_class = 'green_fov_class' in df.columns

    if has_fov_class:
        for channel, ch_col in [('mHTT1a', 'green'), ('full-length mHTT', 'orange')]:
            for region in ['striatum', 'cortex']:
                print(f"\n  {channel} - {region.capitalize()}:")

                # Extreme FOVs (sorted by mRNA per cell, descending)
                df_extreme = filter_fovs(df, genotype='Q111', probe_type='experimental',
                                        region_type=region, min_nuclei=40,
                                        fov_class='extreme', channel=channel)

                mrna_col = f'{ch_col}_clustered_mrna_per_cell'
                if len(df_extreme) > 0 and mrna_col in df_extreme.columns:
                    df_extreme = df_extreme.sort_values(mrna_col, ascending=False)
                    recommendations[f'{ch_col}_extreme_{region}'] = df_extreme.head(5)
                    best = df_extreme.iloc[0]
                    print(f"    EXTREME: {len(df_extreme)} FOVs")
                    print(f"      Best: {best['fov_key']}")
                    print(f"        mRNA/cell: {best.get(mrna_col, 0):.2f}")

                # Normal FOVs (sorted by mRNA per cell, descending to get "best" normal examples)
                df_normal = filter_fovs(df, genotype='Q111', probe_type='experimental',
                                       region_type=region, min_nuclei=40,
                                       fov_class='normal', channel=channel)

                if len(df_normal) > 0 and mrna_col in df_normal.columns:
                    df_normal = df_normal.sort_values(mrna_col, ascending=False)
                    recommendations[f'{ch_col}_normal_{region}'] = df_normal.head(5)
                    best = df_normal.iloc[0]
                    print(f"    NORMAL: {len(df_normal)} FOVs")
                    print(f"      Best: {best['fov_key']}")
                    print(f"        mRNA/cell: {best.get(mrna_col, 0):.2f}")
    else:
        print("\n  FOV class data not available. Run with FOV-level data to see extreme/normal classification.")

    return recommendations


def main():
    parser = argparse.ArgumentParser(
        description="Smart Image Browser for Figure Example Selection",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Interactive mode
  python image_browser.py

  # List all slides
  python image_browser.py --list-slides

  # Filter by genotype and region
  python image_browser.py --genotype Q111 --region striatum

  # Filter by FOV class (extreme vs normal)
  python image_browser.py --fov-class extreme --channel mHTT1a
  python image_browser.py --fov-class normal --channel full-length --region striatum

  # Get recommendations for figure panels
  python image_browser.py --recommend

  # View a specific NPZ file
  python image_browser.py --view /path/to/file.npz
        """
    )

    parser.add_argument('--h5-path', type=str, default=None,
                        help='Path to H5 file (default: from results_config)')
    parser.add_argument('--genotype', type=str, choices=['Q111', 'Wildtype', 'WT'],
                        help='Filter by genotype')
    parser.add_argument('--probe', type=str,
                        choices=['experimental', 'positive_control', 'negative_control'],
                        help='Filter by probe type')
    parser.add_argument('--region', type=str, choices=['striatum', 'cortex'],
                        help='Filter by brain region type')
    parser.add_argument('--slide', type=str, help='Filter by slide (e.g., m3a1)')
    parser.add_argument('--min-spots', type=int, help='Minimum total spots')
    parser.add_argument('--min-nuclei', type=int, default=40, help='Minimum nuclei count')
    parser.add_argument('--fov-class', type=str, choices=['extreme', 'normal'],
                        help='Filter by FOV class (extreme > WT P95, normal ≤ WT P95)')
    parser.add_argument('--channel', type=str, choices=['mHTT1a', 'full-length', 'green', 'orange'],
                        help='Channel for FOV class filtering (default: mHTT1a)')
    parser.add_argument('--list-slides', action='store_true', help='List all available slides')
    parser.add_argument('--recommend', action='store_true',
                        help='Show recommended FOVs for figure panels')
    parser.add_argument('--view', type=str, help='View a specific NPZ file')
    parser.add_argument('--interactive', '-i', action='store_true',
                        help='Enter interactive mode')
    parser.add_argument('--show', type=int, default=20,
                        help='Number of results to show (default: 20)')
    parser.add_argument('--no-fov-data', action='store_true',
                        help='Skip loading FOV-level mRNA quantification data')

    args = parser.parse_args()

    # View mode - just launch viewer
    if args.view:
        if os.path.exists(args.view):
            view_fov(args.view)
        else:
            print(f"File not found: {args.view}")
        return

    # Load H5 metadata
    print("\n" + "="*100)
    print("LOADING DATA")
    print("="*100)

    df = load_fov_metadata(args.h5_path)

    # Load and merge FOV-level quantification data (with extreme/normal classification)
    if not args.no_fov_data:
        df_fov, wt_p95_thresholds = load_fov_level_data()
        if df_fov is not None:
            df = merge_h5_with_fov_data(df, df_fov)
            print(f"Merged FOV-level data. Total FOVs: {len(df)}")

    # List slides mode
    if args.list_slides:
        print("\nAvailable slides:")
        for slide in sorted(df['slide_std'].dropna().unique()):
            count = len(df[df['slide_std'] == slide])
            print(f"  {slide}: {count} FOVs")
        return

    # Recommendations mode
    if args.recommend:
        get_example_fovs_for_figures(df)
        return

    # Apply filters
    df_filtered = filter_fovs(
        df,
        genotype=args.genotype,
        probe_type=args.probe,
        region_type=args.region,
        min_spots=args.min_spots,
        min_nuclei=args.min_nuclei,
        slide=args.slide,
        fov_class=args.fov_class,
        channel=args.channel
    )

    # Show results
    print_fov_summary(df_filtered, n_show=args.show)

    # Interactive mode
    if args.interactive or (not any([args.genotype, args.probe, args.region,
                                      args.slide, args.min_spots, args.list_slides,
                                      args.recommend, args.fov_class])):
        interactive_browser(df_filtered)


if __name__ == '__main__':
    main()
